{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-24 22:11:04--  https://mmaisharables.blob.core.windows.net/uc2/UC2_DATA.tar.gz\n",
      "Resolving mmaisharables.blob.core.windows.net (mmaisharables.blob.core.windows.net)... 20.150.90.68\n",
      "Connecting to mmaisharables.blob.core.windows.net (mmaisharables.blob.core.windows.net)|20.150.90.68|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9777118183 (9.1G) [application/gzip]\n",
      "Saving to: ‘UC2_DATA.tar.gz’\n",
      "\n",
      " 1% [                                       ] 142,614,528 8.51MB/s  eta 33m 35s^C\n"
     ]
    }
   ],
   "source": [
    "# !wget https://mmaisharables.blob.core.windows.net/uc2/UC2_DATA.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc2 = torch.load(\"UC2_DATA/pretrain/uc2/ckpt/model_step_200000.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250002, 768] \t roberta.embeddings.word_embeddings.weight\n",
      "[514, 768] \t roberta.embeddings.position_embeddings.weight\n",
      "[2, 768] \t roberta.embeddings.new_token_type_embeddings.weight\n",
      "[768] \t roberta.embeddings.LayerNorm.weight\n",
      "[768] \t roberta.embeddings.LayerNorm.bias\n",
      "[768, 2048] \t roberta.img_embeddings.img_linear.weight\n",
      "[768] \t roberta.img_embeddings.img_linear.bias\n",
      "[768] \t roberta.img_embeddings.img_layer_norm.weight\n",
      "[768] \t roberta.img_embeddings.img_layer_norm.bias\n",
      "[768] \t roberta.img_embeddings.pos_layer_norm.weight\n",
      "[768] \t roberta.img_embeddings.pos_layer_norm.bias\n",
      "[768, 7] \t roberta.img_embeddings.pos_linear.weight\n",
      "[768] \t roberta.img_embeddings.pos_linear.bias\n",
      "[2, 2048] \t roberta.img_embeddings.mask_embedding.weight\n",
      "[768] \t roberta.img_embeddings.LayerNorm.weight\n",
      "[768] \t roberta.img_embeddings.LayerNorm.bias\n",
      "[768, 768] \t roberta.encoder.layer.0.attention.self.query.weight\n",
      "[768] \t roberta.encoder.layer.0.attention.self.query.bias\n",
      "[768, 768] \t roberta.encoder.layer.0.attention.self.key.weight\n",
      "[768] \t roberta.encoder.layer.0.attention.self.key.bias\n",
      "[768, 768] \t roberta.encoder.layer.0.attention.self.value.weight\n",
      "[768] \t roberta.encoder.layer.0.attention.self.value.bias\n",
      "[768, 768] \t roberta.encoder.layer.0.attention.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.0.attention.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "[3072, 768] \t roberta.encoder.layer.0.intermediate.dense.weight\n",
      "[3072] \t roberta.encoder.layer.0.intermediate.dense.bias\n",
      "[768, 3072] \t roberta.encoder.layer.0.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.0.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.0.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.0.output.LayerNorm.bias\n",
      "[768, 768] \t roberta.encoder.layer.1.attention.self.query.weight\n",
      "[768] \t roberta.encoder.layer.1.attention.self.query.bias\n",
      "[768, 768] \t roberta.encoder.layer.1.attention.self.key.weight\n",
      "[768] \t roberta.encoder.layer.1.attention.self.key.bias\n",
      "[768, 768] \t roberta.encoder.layer.1.attention.self.value.weight\n",
      "[768] \t roberta.encoder.layer.1.attention.self.value.bias\n",
      "[768, 768] \t roberta.encoder.layer.1.attention.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.1.attention.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "[3072, 768] \t roberta.encoder.layer.1.intermediate.dense.weight\n",
      "[3072] \t roberta.encoder.layer.1.intermediate.dense.bias\n",
      "[768, 3072] \t roberta.encoder.layer.1.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.1.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.1.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.1.output.LayerNorm.bias\n",
      "[768, 768] \t roberta.encoder.layer.2.attention.self.query.weight\n",
      "[768] \t roberta.encoder.layer.2.attention.self.query.bias\n",
      "[768, 768] \t roberta.encoder.layer.2.attention.self.key.weight\n",
      "[768] \t roberta.encoder.layer.2.attention.self.key.bias\n",
      "[768, 768] \t roberta.encoder.layer.2.attention.self.value.weight\n",
      "[768] \t roberta.encoder.layer.2.attention.self.value.bias\n",
      "[768, 768] \t roberta.encoder.layer.2.attention.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.2.attention.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "[3072, 768] \t roberta.encoder.layer.2.intermediate.dense.weight\n",
      "[3072] \t roberta.encoder.layer.2.intermediate.dense.bias\n",
      "[768, 3072] \t roberta.encoder.layer.2.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.2.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.2.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.2.output.LayerNorm.bias\n",
      "[768, 768] \t roberta.encoder.layer.3.attention.self.query.weight\n",
      "[768] \t roberta.encoder.layer.3.attention.self.query.bias\n",
      "[768, 768] \t roberta.encoder.layer.3.attention.self.key.weight\n",
      "[768] \t roberta.encoder.layer.3.attention.self.key.bias\n",
      "[768, 768] \t roberta.encoder.layer.3.attention.self.value.weight\n",
      "[768] \t roberta.encoder.layer.3.attention.self.value.bias\n",
      "[768, 768] \t roberta.encoder.layer.3.attention.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.3.attention.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "[3072, 768] \t roberta.encoder.layer.3.intermediate.dense.weight\n",
      "[3072] \t roberta.encoder.layer.3.intermediate.dense.bias\n",
      "[768, 3072] \t roberta.encoder.layer.3.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.3.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.3.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.3.output.LayerNorm.bias\n",
      "[768, 768] \t roberta.encoder.layer.4.attention.self.query.weight\n",
      "[768] \t roberta.encoder.layer.4.attention.self.query.bias\n",
      "[768, 768] \t roberta.encoder.layer.4.attention.self.key.weight\n",
      "[768] \t roberta.encoder.layer.4.attention.self.key.bias\n",
      "[768, 768] \t roberta.encoder.layer.4.attention.self.value.weight\n",
      "[768] \t roberta.encoder.layer.4.attention.self.value.bias\n",
      "[768, 768] \t roberta.encoder.layer.4.attention.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.4.attention.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "[3072, 768] \t roberta.encoder.layer.4.intermediate.dense.weight\n",
      "[3072] \t roberta.encoder.layer.4.intermediate.dense.bias\n",
      "[768, 3072] \t roberta.encoder.layer.4.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.4.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.4.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.4.output.LayerNorm.bias\n",
      "[768, 768] \t roberta.encoder.layer.5.attention.self.query.weight\n",
      "[768] \t roberta.encoder.layer.5.attention.self.query.bias\n",
      "[768, 768] \t roberta.encoder.layer.5.attention.self.key.weight\n",
      "[768] \t roberta.encoder.layer.5.attention.self.key.bias\n",
      "[768, 768] \t roberta.encoder.layer.5.attention.self.value.weight\n",
      "[768] \t roberta.encoder.layer.5.attention.self.value.bias\n",
      "[768, 768] \t roberta.encoder.layer.5.attention.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.5.attention.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "[3072, 768] \t roberta.encoder.layer.5.intermediate.dense.weight\n",
      "[3072] \t roberta.encoder.layer.5.intermediate.dense.bias\n",
      "[768, 3072] \t roberta.encoder.layer.5.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.5.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.5.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.5.output.LayerNorm.bias\n",
      "[768, 768] \t roberta.encoder.layer.6.attention.self.query.weight\n",
      "[768] \t roberta.encoder.layer.6.attention.self.query.bias\n",
      "[768, 768] \t roberta.encoder.layer.6.attention.self.key.weight\n",
      "[768] \t roberta.encoder.layer.6.attention.self.key.bias\n",
      "[768, 768] \t roberta.encoder.layer.6.attention.self.value.weight\n",
      "[768] \t roberta.encoder.layer.6.attention.self.value.bias\n",
      "[768, 768] \t roberta.encoder.layer.6.attention.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.6.attention.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "[3072, 768] \t roberta.encoder.layer.6.intermediate.dense.weight\n",
      "[3072] \t roberta.encoder.layer.6.intermediate.dense.bias\n",
      "[768, 3072] \t roberta.encoder.layer.6.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.6.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.6.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.6.output.LayerNorm.bias\n",
      "[768, 768] \t roberta.encoder.layer.7.attention.self.query.weight\n",
      "[768] \t roberta.encoder.layer.7.attention.self.query.bias\n",
      "[768, 768] \t roberta.encoder.layer.7.attention.self.key.weight\n",
      "[768] \t roberta.encoder.layer.7.attention.self.key.bias\n",
      "[768, 768] \t roberta.encoder.layer.7.attention.self.value.weight\n",
      "[768] \t roberta.encoder.layer.7.attention.self.value.bias\n",
      "[768, 768] \t roberta.encoder.layer.7.attention.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.7.attention.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "[3072, 768] \t roberta.encoder.layer.7.intermediate.dense.weight\n",
      "[3072] \t roberta.encoder.layer.7.intermediate.dense.bias\n",
      "[768, 3072] \t roberta.encoder.layer.7.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.7.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.7.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.7.output.LayerNorm.bias\n",
      "[768, 768] \t roberta.encoder.layer.8.attention.self.query.weight\n",
      "[768] \t roberta.encoder.layer.8.attention.self.query.bias\n",
      "[768, 768] \t roberta.encoder.layer.8.attention.self.key.weight\n",
      "[768] \t roberta.encoder.layer.8.attention.self.key.bias\n",
      "[768, 768] \t roberta.encoder.layer.8.attention.self.value.weight\n",
      "[768] \t roberta.encoder.layer.8.attention.self.value.bias\n",
      "[768, 768] \t roberta.encoder.layer.8.attention.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.8.attention.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "[3072, 768] \t roberta.encoder.layer.8.intermediate.dense.weight\n",
      "[3072] \t roberta.encoder.layer.8.intermediate.dense.bias\n",
      "[768, 3072] \t roberta.encoder.layer.8.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.8.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.8.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.8.output.LayerNorm.bias\n",
      "[768, 768] \t roberta.encoder.layer.9.attention.self.query.weight\n",
      "[768] \t roberta.encoder.layer.9.attention.self.query.bias\n",
      "[768, 768] \t roberta.encoder.layer.9.attention.self.key.weight\n",
      "[768] \t roberta.encoder.layer.9.attention.self.key.bias\n",
      "[768, 768] \t roberta.encoder.layer.9.attention.self.value.weight\n",
      "[768] \t roberta.encoder.layer.9.attention.self.value.bias\n",
      "[768, 768] \t roberta.encoder.layer.9.attention.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.9.attention.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "[3072, 768] \t roberta.encoder.layer.9.intermediate.dense.weight\n",
      "[3072] \t roberta.encoder.layer.9.intermediate.dense.bias\n",
      "[768, 3072] \t roberta.encoder.layer.9.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.9.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.9.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.9.output.LayerNorm.bias\n",
      "[768, 768] \t roberta.encoder.layer.10.attention.self.query.weight\n",
      "[768] \t roberta.encoder.layer.10.attention.self.query.bias\n",
      "[768, 768] \t roberta.encoder.layer.10.attention.self.key.weight\n",
      "[768] \t roberta.encoder.layer.10.attention.self.key.bias\n",
      "[768, 768] \t roberta.encoder.layer.10.attention.self.value.weight\n",
      "[768] \t roberta.encoder.layer.10.attention.self.value.bias\n",
      "[768, 768] \t roberta.encoder.layer.10.attention.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.10.attention.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "[3072, 768] \t roberta.encoder.layer.10.intermediate.dense.weight\n",
      "[3072] \t roberta.encoder.layer.10.intermediate.dense.bias\n",
      "[768, 3072] \t roberta.encoder.layer.10.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.10.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.10.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.10.output.LayerNorm.bias\n",
      "[768, 768] \t roberta.encoder.layer.11.attention.self.query.weight\n",
      "[768] \t roberta.encoder.layer.11.attention.self.query.bias\n",
      "[768, 768] \t roberta.encoder.layer.11.attention.self.key.weight\n",
      "[768] \t roberta.encoder.layer.11.attention.self.key.bias\n",
      "[768, 768] \t roberta.encoder.layer.11.attention.self.value.weight\n",
      "[768] \t roberta.encoder.layer.11.attention.self.value.bias\n",
      "[768, 768] \t roberta.encoder.layer.11.attention.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.11.attention.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "[3072, 768] \t roberta.encoder.layer.11.intermediate.dense.weight\n",
      "[3072] \t roberta.encoder.layer.11.intermediate.dense.bias\n",
      "[768, 3072] \t roberta.encoder.layer.11.output.dense.weight\n",
      "[768] \t roberta.encoder.layer.11.output.dense.bias\n",
      "[768] \t roberta.encoder.layer.11.output.LayerNorm.weight\n",
      "[768] \t roberta.encoder.layer.11.output.LayerNorm.bias\n",
      "[768, 768] \t roberta.pooler.dense.weight\n",
      "[768] \t roberta.pooler.dense.bias\n",
      "[250002] \t cls.bias\n",
      "[768, 768] \t cls.dense.weight\n",
      "[768] \t cls.dense.bias\n",
      "[768] \t cls.layer_norm.weight\n",
      "[768] \t cls.layer_norm.bias\n",
      "[250002, 768] \t cls.decoder.weight\n",
      "[250002] \t cls.decoder.bias\n",
      "[1354] \t vis_cls.bias\n",
      "[768, 768] \t vis_cls.dense.weight\n",
      "[768] \t vis_cls.dense.bias\n",
      "[768] \t vis_cls.layer_norm.weight\n",
      "[768] \t vis_cls.layer_norm.bias\n",
      "[1354, 768] \t vis_cls.decoder.weight\n",
      "[1354] \t vis_cls.decoder.bias\n",
      "[768, 2048] \t feat_regress.weight\n",
      "[2048] \t feat_regress.bias\n",
      "[768, 768] \t feat_regress.net.0.weight\n",
      "[768] \t feat_regress.net.0.bias\n",
      "[768] \t feat_regress.net.2.weight\n",
      "[768] \t feat_regress.net.2.bias\n",
      "[768, 768] \t region_classifier.net.0.weight\n",
      "[768] \t region_classifier.net.0.bias\n",
      "[768] \t region_classifier.net.2.weight\n",
      "[768] \t region_classifier.net.2.bias\n",
      "[1601, 768] \t region_classifier.net.3.weight\n",
      "[1601] \t region_classifier.net.3.bias\n",
      "[2, 768] \t itm_output.weight\n",
      "[2] \t itm_output.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in uc2.items():\n",
    "    print(list(v.size()), '\\t', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model's visual targets are  ['0']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "from volta.config import BertConfig\n",
    "from volta.encoders import BertForVLPreTraining\n",
    "\n",
    "\n",
    "# # Inputs\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--input_fn\", type=str, default=\"Epoch20_LXRT.pth\")\n",
    "# parser.add_argument(\"--output_fn\", type=str, default=\"lxmert_checkpoint_19.bin\")\n",
    "# parser.add_argument(\"--verbose\", action=\"store_true\", default=False)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# Load original checkpoint\n",
    "# original_ckpt = torch.load(args.input_fn, map_location=\"cpu\")\n",
    "\n",
    "# Create corresponding VOLTA model\n",
    "config_file = \"../config/uc2_base.json\"\n",
    "config = BertConfig.from_json_file(config_file)\n",
    "model = BertForVLPreTraining.from_pretrained(\"/science/image/nlp-datasets/emanuele/huggingface/xlm-roberta-base\", config=config, default_gpu=True, from_hf=True)\n",
    "trg_dict = model.state_dict()\n",
    "\n",
    "# # Map original parameters onto VOLTA ones\n",
    "# first_xlayer = config.tv_attn_sublayers[0]\n",
    "# volta2original = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForVLPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): UC2Embeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768)\n",
       "      (new_token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (image_embeddings): Linear(in_features=2048, out_features=768, bias=True)\n",
       "      (image_location_embeddings): Linear(in_features=7, out_features=768, bias=True)\n",
       "      (image_token_type_embeddings): Embedding(2, 768)\n",
       "      (image_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (image_location_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (4): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (5): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (6): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (7): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (8): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (9): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (10): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (11): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (12): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (13): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (14): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (15): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (16): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (17): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (18): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (19): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (20): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (21): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (22): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (23): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (t_pooler): BertTextPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=250002, bias=False)\n",
       "    )\n",
       "    (bi_seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "    (imagePredictions): BertImagePredictionHead(\n",
       "      (transform): BertImgPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder_dict): ModuleDict(\n",
       "        (0): Linear(in_features=768, out_features=1601, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (loss_fct): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250002, 768] \t bert.embeddings.word_embeddings.weight\n",
      "[514, 768] \t bert.embeddings.position_embeddings.weight\n",
      "[2, 768] \t bert.embeddings.new_token_type_embeddings.weight\n",
      "[768] \t bert.embeddings.LayerNorm.weight\n",
      "[768] \t bert.embeddings.LayerNorm.bias\n",
      "[768, 2048] \t bert.embeddings.image_embeddings.weight\n",
      "[768] \t bert.embeddings.image_embeddings.bias\n",
      "[768, 7] \t bert.embeddings.image_location_embeddings.weight\n",
      "[768] \t bert.embeddings.image_location_embeddings.bias\n",
      "[2, 768] \t bert.embeddings.image_token_type_embeddings.weight\n",
      "[768] \t bert.embeddings.image_layer_norm.weight\n",
      "[768] \t bert.embeddings.image_layer_norm.bias\n",
      "[768] \t bert.embeddings.image_location_layer_norm.weight\n",
      "[768] \t bert.embeddings.image_location_layer_norm.bias\n",
      "[768] \t bert.embeddings.v_LayerNorm.weight\n",
      "[768] \t bert.embeddings.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.0.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.0.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.0.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.0.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.0.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.0.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.0.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.0.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.0.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.0.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.0.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.0.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.1.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.1.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.1.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.1.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.1.output.dense.weight\n",
      "[768] \t bert.encoder.layer.1.output.dense.bias\n",
      "[768] \t bert.encoder.layer.1.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.1.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.1.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.1.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.1.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.1.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.2.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.2.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.2.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.2.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.2.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.2.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.2.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.2.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.2.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.2.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.2.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.2.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.3.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.3.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.3.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.3.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.3.output.dense.weight\n",
      "[768] \t bert.encoder.layer.3.output.dense.bias\n",
      "[768] \t bert.encoder.layer.3.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.3.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.3.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.3.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.3.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.3.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.4.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.4.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.4.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.4.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.4.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.4.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.4.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.4.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.4.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.4.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.4.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.4.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.5.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.5.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.5.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.5.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.5.output.dense.weight\n",
      "[768] \t bert.encoder.layer.5.output.dense.bias\n",
      "[768] \t bert.encoder.layer.5.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.5.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.5.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.5.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.5.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.5.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.6.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.6.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.6.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.6.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.6.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.6.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.6.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.6.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.6.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.6.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.6.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.6.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.7.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.7.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.7.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.7.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.7.output.dense.weight\n",
      "[768] \t bert.encoder.layer.7.output.dense.bias\n",
      "[768] \t bert.encoder.layer.7.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.7.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.7.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.7.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.7.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.7.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.8.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.8.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.8.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.8.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.8.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.8.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.8.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.8.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.8.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.8.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.8.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.8.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.9.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.9.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.9.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.9.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.9.output.dense.weight\n",
      "[768] \t bert.encoder.layer.9.output.dense.bias\n",
      "[768] \t bert.encoder.layer.9.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.9.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.9.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.9.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.9.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.9.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.10.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.10.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.10.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.10.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.10.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.10.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.10.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.10.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.10.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.10.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.10.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.10.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.11.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.11.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.11.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.11.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.11.output.dense.weight\n",
      "[768] \t bert.encoder.layer.11.output.dense.bias\n",
      "[768] \t bert.encoder.layer.11.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.11.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.11.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.11.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.11.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.11.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.12.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.12.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.12.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.12.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.12.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.12.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.12.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.12.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.12.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.12.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.12.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.12.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.13.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.13.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.13.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.13.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.13.output.dense.weight\n",
      "[768] \t bert.encoder.layer.13.output.dense.bias\n",
      "[768] \t bert.encoder.layer.13.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.13.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.13.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.13.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.13.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.13.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.14.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.14.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.14.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.14.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.14.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.14.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.14.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.14.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.14.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.14.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.14.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.14.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.15.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.15.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.15.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.15.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.15.output.dense.weight\n",
      "[768] \t bert.encoder.layer.15.output.dense.bias\n",
      "[768] \t bert.encoder.layer.15.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.15.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.15.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.15.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.15.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.15.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.16.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.16.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.16.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.16.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.16.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.16.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.16.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.16.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.16.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.16.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.16.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.16.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.17.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.17.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.17.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.17.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.17.output.dense.weight\n",
      "[768] \t bert.encoder.layer.17.output.dense.bias\n",
      "[768] \t bert.encoder.layer.17.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.17.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.17.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.17.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.17.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.17.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.18.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.18.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.18.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.18.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.18.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.18.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.18.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.18.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.18.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.18.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.18.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.18.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.19.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.19.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.19.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.19.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.19.output.dense.weight\n",
      "[768] \t bert.encoder.layer.19.output.dense.bias\n",
      "[768] \t bert.encoder.layer.19.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.19.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.19.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.19.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.19.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.19.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.20.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.20.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.20.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.20.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.20.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.20.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.20.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.20.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.20.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.20.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.20.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.20.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.21.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.21.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.21.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.21.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.21.output.dense.weight\n",
      "[768] \t bert.encoder.layer.21.output.dense.bias\n",
      "[768] \t bert.encoder.layer.21.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.21.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.21.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.21.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.21.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.21.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.22.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.22.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.22.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.22.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.22.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.22.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.22.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.22.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.22.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.22.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.22.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.22.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.23.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.23.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.23.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.23.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.23.output.dense.weight\n",
      "[768] \t bert.encoder.layer.23.output.dense.bias\n",
      "[768] \t bert.encoder.layer.23.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.23.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.23.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.23.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.23.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.23.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.t_pooler.dense.weight\n",
      "[768] \t bert.t_pooler.dense.bias\n",
      "[250002] \t cls.predictions.bias\n",
      "[768, 768] \t cls.predictions.transform.dense.weight\n",
      "[768] \t cls.predictions.transform.dense.bias\n",
      "[768] \t cls.predictions.transform.LayerNorm.weight\n",
      "[768] \t cls.predictions.transform.LayerNorm.bias\n",
      "[250002, 768] \t cls.predictions.decoder.weight\n",
      "[2, 768] \t cls.bi_seq_relationship.weight\n",
      "[2] \t cls.bi_seq_relationship.bias\n",
      "[768, 768] \t cls.imagePredictions.transform.dense.weight\n",
      "[768] \t cls.imagePredictions.transform.dense.bias\n",
      "[768] \t cls.imagePredictions.transform.LayerNorm.weight\n",
      "[768] \t cls.imagePredictions.transform.LayerNorm.bias\n",
      "[1601, 768] \t cls.imagePredictions.decoder_dict.0.weight\n",
      "[1601] \t cls.imagePredictions.decoder_dict.0.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in trg_dict.items():\n",
    "    print(list(v.size()), '\\t', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "volta2original = dict()\n",
    "volta_keys = set(trg_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta.img_embeddings.mask_embedding.weight \t bert.embeddings.mask_embedding.weight\n",
      "cls.decoder.bias \t cls.predictions.decoder.bias\n",
      "vis_cls.bias \t vis_cls.predictions.bias\n",
      "vis_cls.dense.weight \t vis_cls.predictions.transform.dense.weight\n",
      "vis_cls.dense.bias \t vis_cls.predictions.transform.dense.bias\n",
      "vis_cls.layer_norm.weight \t vis_cls.predictions.transform.LayerNorm.weight\n",
      "vis_cls.layer_norm.bias \t vis_cls.predictions.transform.LayerNorm.bias\n",
      "vis_cls.decoder.weight \t vis_cls.predictions.decoder.weight\n",
      "vis_cls.decoder.bias \t vis_cls.predictions.decoder.bias\n",
      "feat_regress.weight \t feat_regress.weight\n",
      "feat_regress.bias \t feat_regress.bias\n",
      "feat_regress.net.0.weight \t feat_regress.net.0.weight\n",
      "feat_regress.net.0.bias \t feat_regress.net.0.bias\n",
      "feat_regress.net.2.weight \t feat_regress.net.2.weight\n",
      "feat_regress.net.2.bias \t feat_regress.net.2.bias\n",
      "region_classifier.net.0.weight \t region_classifier.net.0.weight\n",
      "region_classifier.net.0.bias \t region_classifier.net.0.bias\n",
      "region_classifier.net.2.weight \t region_classifier.net.2.weight\n",
      "region_classifier.net.2.bias \t region_classifier.net.2.bias\n",
      "region_classifier.net.3.weight \t region_classifier.net.3.weight\n",
      "region_classifier.net.3.bias \t region_classifier.net.3.bias\n"
     ]
    }
   ],
   "source": [
    "for k in uc2.keys():\n",
    "    ln = str(k)\n",
    "    ln = ln.replace(\"roberta\", \"bert\")\n",
    "    \n",
    "    ln = ln.replace(\"img_embeddings\", \"embeddings\")\n",
    "    ln = ln.replace(\"img_linear\", \"image_embeddings\")\n",
    "    ln = ln.replace(\"pos_linear\", \"image_location_embeddings\")\n",
    "    ln = ln.replace(\"img_layer_norm\", \"image_layer_norm\")\n",
    "    ln = ln.replace(\"pos_layer_norm\", \"image_location_layer_norm\")\n",
    "    \n",
    "    ln = ln.replace('attention.self', 'attention_self')\n",
    "    ln = ln.replace('attention.output', 'attention_output')\n",
    "    if '.layer.' in ln:\n",
    "        num = int(ln.split(\".\")[3])\n",
    "        new = 2*num + ('.intermediate.' in ln or '.output.' in ln)\n",
    "        ln = ln.replace(f\".{num}.\", f\".{new}.\")\n",
    "        \n",
    "    ln = ln.replace(\"pooler\", \"t_pooler\")\n",
    "    ln = ln.replace(\"cls.dense\", \"cls.predictions.transform.dense\")\n",
    "    ln = ln.replace(\"cls.layer_norm\", \"cls.predictions.transform.LayerNorm\")\n",
    "    ln = ln.replace(\"cls.bias\", \"cls.predictions.bias\")\n",
    "    ln = ln.replace(\"cls.decoder\", \"cls.predictions.decoder\")\n",
    "    ln = ln.replace(\"itm_output\", \"cls.bi_seq_relationship\")\n",
    "    \n",
    "    if ln not in volta_keys:\n",
    "        print(k, \"\\t\", ln)\n",
    "    else:\n",
    "        volta2original[ln] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_ckpt = uc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight <- roberta.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight <- roberta.embeddings.position_embeddings.weight\n",
      "bert.embeddings.new_token_type_embeddings.weight <- roberta.embeddings.new_token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight <- roberta.img_embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias <- roberta.img_embeddings.LayerNorm.bias\n",
      "bert.embeddings.image_embeddings.weight <- roberta.img_embeddings.img_linear.weight\n",
      "bert.embeddings.image_embeddings.bias <- roberta.img_embeddings.img_linear.bias\n",
      "bert.embeddings.image_layer_norm.weight <- roberta.img_embeddings.img_layer_norm.weight\n",
      "bert.embeddings.image_layer_norm.bias <- roberta.img_embeddings.img_layer_norm.bias\n",
      "bert.embeddings.image_location_layer_norm.weight <- roberta.img_embeddings.pos_layer_norm.weight\n",
      "bert.embeddings.image_location_layer_norm.bias <- roberta.img_embeddings.pos_layer_norm.bias\n",
      "bert.embeddings.image_location_embeddings.weight <- roberta.img_embeddings.pos_linear.weight\n",
      "bert.embeddings.image_location_embeddings.bias <- roberta.img_embeddings.pos_linear.bias\n",
      "bert.encoder.layer.0.attention_self.query.weight <- roberta.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention_self.query.bias <- roberta.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention_self.key.weight <- roberta.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention_self.key.bias <- roberta.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention_self.value.weight <- roberta.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention_self.value.bias <- roberta.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention_output.dense.weight <- roberta.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention_output.dense.bias <- roberta.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention_output.LayerNorm.weight <- roberta.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention_output.LayerNorm.bias <- roberta.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight <- roberta.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias <- roberta.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight <- roberta.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias <- roberta.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight <- roberta.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias <- roberta.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention_self.query.weight <- roberta.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention_self.query.bias <- roberta.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention_self.key.weight <- roberta.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention_self.key.bias <- roberta.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention_self.value.weight <- roberta.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention_self.value.bias <- roberta.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention_output.dense.weight <- roberta.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention_output.dense.bias <- roberta.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention_output.LayerNorm.weight <- roberta.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention_output.LayerNorm.bias <- roberta.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight <- roberta.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias <- roberta.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight <- roberta.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias <- roberta.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight <- roberta.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias <- roberta.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention_self.query.weight <- roberta.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention_self.query.bias <- roberta.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention_self.key.weight <- roberta.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention_self.key.bias <- roberta.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention_self.value.weight <- roberta.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention_self.value.bias <- roberta.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention_output.dense.weight <- roberta.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention_output.dense.bias <- roberta.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention_output.LayerNorm.weight <- roberta.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention_output.LayerNorm.bias <- roberta.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight <- roberta.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias <- roberta.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight <- roberta.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias <- roberta.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight <- roberta.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias <- roberta.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention_self.query.weight <- roberta.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention_self.query.bias <- roberta.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention_self.key.weight <- roberta.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention_self.key.bias <- roberta.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention_self.value.weight <- roberta.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention_self.value.bias <- roberta.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention_output.dense.weight <- roberta.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention_output.dense.bias <- roberta.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention_output.LayerNorm.weight <- roberta.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention_output.LayerNorm.bias <- roberta.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight <- roberta.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias <- roberta.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight <- roberta.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias <- roberta.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight <- roberta.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias <- roberta.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention_self.query.weight <- roberta.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention_self.query.bias <- roberta.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention_self.key.weight <- roberta.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention_self.key.bias <- roberta.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention_self.value.weight <- roberta.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention_self.value.bias <- roberta.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention_output.dense.weight <- roberta.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention_output.dense.bias <- roberta.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention_output.LayerNorm.weight <- roberta.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention_output.LayerNorm.bias <- roberta.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight <- roberta.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias <- roberta.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight <- roberta.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias <- roberta.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight <- roberta.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias <- roberta.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention_self.query.weight <- roberta.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention_self.query.bias <- roberta.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention_self.key.weight <- roberta.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention_self.key.bias <- roberta.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention_self.value.weight <- roberta.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention_self.value.bias <- roberta.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention_output.dense.weight <- roberta.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention_output.dense.bias <- roberta.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention_output.LayerNorm.weight <- roberta.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention_output.LayerNorm.bias <- roberta.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight <- roberta.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias <- roberta.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight <- roberta.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias <- roberta.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight <- roberta.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias <- roberta.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.12.attention_self.query.weight <- roberta.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.12.attention_self.query.bias <- roberta.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.12.attention_self.key.weight <- roberta.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.12.attention_self.key.bias <- roberta.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.12.attention_self.value.weight <- roberta.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.12.attention_self.value.bias <- roberta.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.12.attention_output.dense.weight <- roberta.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.12.attention_output.dense.bias <- roberta.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.12.attention_output.LayerNorm.weight <- roberta.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.12.attention_output.LayerNorm.bias <- roberta.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.13.intermediate.dense.weight <- roberta.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.13.intermediate.dense.bias <- roberta.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.13.output.dense.weight <- roberta.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.13.output.dense.bias <- roberta.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.13.output.LayerNorm.weight <- roberta.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.13.output.LayerNorm.bias <- roberta.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.14.attention_self.query.weight <- roberta.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.14.attention_self.query.bias <- roberta.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.14.attention_self.key.weight <- roberta.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.14.attention_self.key.bias <- roberta.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.14.attention_self.value.weight <- roberta.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.14.attention_self.value.bias <- roberta.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.14.attention_output.dense.weight <- roberta.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.14.attention_output.dense.bias <- roberta.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.14.attention_output.LayerNorm.weight <- roberta.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.14.attention_output.LayerNorm.bias <- roberta.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.15.intermediate.dense.weight <- roberta.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.15.intermediate.dense.bias <- roberta.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.15.output.dense.weight <- roberta.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.15.output.dense.bias <- roberta.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.15.output.LayerNorm.weight <- roberta.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.15.output.LayerNorm.bias <- roberta.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.16.attention_self.query.weight <- roberta.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.16.attention_self.query.bias <- roberta.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.16.attention_self.key.weight <- roberta.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.16.attention_self.key.bias <- roberta.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.16.attention_self.value.weight <- roberta.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.16.attention_self.value.bias <- roberta.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.16.attention_output.dense.weight <- roberta.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.16.attention_output.dense.bias <- roberta.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.16.attention_output.LayerNorm.weight <- roberta.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.16.attention_output.LayerNorm.bias <- roberta.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.17.intermediate.dense.weight <- roberta.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.17.intermediate.dense.bias <- roberta.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.17.output.dense.weight <- roberta.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.17.output.dense.bias <- roberta.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.17.output.LayerNorm.weight <- roberta.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.17.output.LayerNorm.bias <- roberta.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.18.attention_self.query.weight <- roberta.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.18.attention_self.query.bias <- roberta.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.18.attention_self.key.weight <- roberta.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.18.attention_self.key.bias <- roberta.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.18.attention_self.value.weight <- roberta.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.18.attention_self.value.bias <- roberta.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.18.attention_output.dense.weight <- roberta.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.18.attention_output.dense.bias <- roberta.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.18.attention_output.LayerNorm.weight <- roberta.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.18.attention_output.LayerNorm.bias <- roberta.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.19.intermediate.dense.weight <- roberta.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.19.intermediate.dense.bias <- roberta.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.19.output.dense.weight <- roberta.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.19.output.dense.bias <- roberta.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.19.output.LayerNorm.weight <- roberta.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.19.output.LayerNorm.bias <- roberta.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.20.attention_self.query.weight <- roberta.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.20.attention_self.query.bias <- roberta.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.20.attention_self.key.weight <- roberta.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.20.attention_self.key.bias <- roberta.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.20.attention_self.value.weight <- roberta.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.20.attention_self.value.bias <- roberta.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.20.attention_output.dense.weight <- roberta.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.20.attention_output.dense.bias <- roberta.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.20.attention_output.LayerNorm.weight <- roberta.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.20.attention_output.LayerNorm.bias <- roberta.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.21.intermediate.dense.weight <- roberta.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.21.intermediate.dense.bias <- roberta.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.21.output.dense.weight <- roberta.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.21.output.dense.bias <- roberta.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.21.output.LayerNorm.weight <- roberta.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.21.output.LayerNorm.bias <- roberta.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.22.attention_self.query.weight <- roberta.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.22.attention_self.query.bias <- roberta.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.22.attention_self.key.weight <- roberta.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.22.attention_self.key.bias <- roberta.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.22.attention_self.value.weight <- roberta.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.22.attention_self.value.bias <- roberta.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.22.attention_output.dense.weight <- roberta.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.22.attention_output.dense.bias <- roberta.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.22.attention_output.LayerNorm.weight <- roberta.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.22.attention_output.LayerNorm.bias <- roberta.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.23.intermediate.dense.weight <- roberta.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.23.intermediate.dense.bias <- roberta.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.23.output.dense.weight <- roberta.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.23.output.dense.bias <- roberta.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.23.output.LayerNorm.weight <- roberta.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.23.output.LayerNorm.bias <- roberta.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.t_pooler.dense.weight <- roberta.pooler.dense.weight\n",
      "bert.t_pooler.dense.bias <- roberta.pooler.dense.bias\n",
      "cls.predictions.bias <- cls.bias\n",
      "cls.predictions.transform.dense.weight <- cls.dense.weight\n",
      "cls.predictions.transform.dense.bias <- cls.dense.bias\n",
      "cls.predictions.transform.LayerNorm.weight <- cls.layer_norm.weight\n",
      "cls.predictions.transform.LayerNorm.bias <- cls.layer_norm.bias\n",
      "cls.predictions.decoder.weight <- cls.decoder.weight\n",
      "cls.bi_seq_relationship.weight <- itm_output.weight\n",
      "cls.bi_seq_relationship.bias <- itm_output.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply mapping\n",
    "for trg, src in volta2original.items():\n",
    "    print(trg, '<-', src)\n",
    "    assert trg_dict[trg].shape == original_ckpt[src].shape\n",
    "    trg_dict[trg] = original_ckpt[src]\n",
    "model.load_state_dict(trg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(768)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model.state_dict()['bert.t_pooler.dense.bias'] == uc2['roberta.pooler.dense.bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(768)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model.state_dict()['bert.encoder.layer.22.attention_self.key.bias'] == model.state_dict()['bert.encoder.layer.22.attention_self.v_key.bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2359296)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.state_dict()['bert.encoder.layer.23.intermediate.dense.weight'] == model.state_dict()['bert.encoder.layer.23.intermediate.v_dense.weight']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2359296"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['bert.encoder.layer.23.intermediate.dense.weight'].size(0) * model.state_dict()['bert.encoder.layer.23.intermediate.dense.weight'].size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UC2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import json\n",
    "\n",
    "import msgpack\n",
    "import msgpack_numpy\n",
    "msgpack_numpy.patch()\n",
    "\n",
    "db_name = \"../../flickr30k/feat_th0.2_max100_min10\"\n",
    "nbb = \"../../flickr30k/nbb_th0.2_max100_min10.json\"\n",
    "name2nbb = json.load(open(f'{nbb}'))\n",
    "\n",
    "env = lmdb.open(f'{db_name}',readonly=True, create=False)\n",
    "txn = env.begin(buffers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"flickr30k_002102835360.npz\"\n",
    "dump = txn.get(filename.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<memory at 0x7f9d2236be88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_nbb = name2nbb[filename]\n",
    "_nbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dump = msgpack.loads(dump, raw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.      , 0.3228  , 0.209   , 0.7686  , 0.209   , 0.446   ],\n",
       "       [0.2742  , 0.7817  , 0.4968  , 0.9985  , 0.2227  , 0.2164  ],\n",
       "       [0.00809 , 0.2183  , 0.11865 , 0.2722  , 0.11053 , 0.05408 ],\n",
       "       [0.      , 0.2064  , 0.1469  , 0.9985  , 0.1469  , 0.792   ],\n",
       "       [0.2632  , 0.3118  , 0.5825  , 0.8413  , 0.319   , 0.53    ],\n",
       "       [0.826   , 0.703   , 0.8657  , 0.801   , 0.03973 , 0.0979  ],\n",
       "       [0.8726  , 0.8184  , 0.98    , 0.9985  , 0.1072  , 0.1797  ],\n",
       "       [0.6143  , 0.4531  , 0.9526  , 0.957   , 0.3386  , 0.504   ],\n",
       "       [0.564   , 0.2546  , 0.8647  , 0.7417  , 0.3008  , 0.4873  ],\n",
       "       [0.      , 0.1522  , 0.774   , 0.848   , 0.774   , 0.6963  ],\n",
       "       [0.769   , 0.7026  , 0.8555  , 0.8174  , 0.0863  , 0.1149  ],\n",
       "       [0.2183  , 0.      , 0.6304  , 0.9985  , 0.4124  , 0.9985  ],\n",
       "       [0.6836  , 0.1381  , 0.808   , 0.205   , 0.1245  , 0.0669  ],\n",
       "       [0.73    , 0.      , 0.9995  , 0.9985  , 0.2693  , 0.9985  ],\n",
       "       [0.657   , 0.05008 , 0.823   , 0.1986  , 0.166   , 0.1486  ],\n",
       "       [0.8154  , 0.256   , 0.925   , 0.355   , 0.109   , 0.09894 ],\n",
       "       [0.615   , 0.06476 , 0.8433  , 0.841   , 0.228   , 0.7764  ],\n",
       "       [0.08514 , 0.185   , 0.2329  , 0.9507  , 0.1477  , 0.7656  ],\n",
       "       [0.6177  , 0.1671  , 0.6953  , 0.2494  , 0.07764 , 0.0823  ],\n",
       "       [0.      , 0.682   , 0.2036  , 0.9985  , 0.2036  , 0.3164  ],\n",
       "       [0.672   , 0.04367 , 0.8223  , 0.2554  , 0.1504  , 0.2115  ],\n",
       "       [0.0244  , 0.745   , 0.184   , 0.9985  , 0.1595  , 0.2532  ],\n",
       "       [0.4702  , 0.1858  , 0.899   , 0.9985  , 0.429   , 0.8125  ],\n",
       "       [0.8335  , 0.3604  , 0.8955  , 0.47    , 0.06195 , 0.10974 ],\n",
       "       [0.1621  , 0.1984  , 0.6606  , 0.9985  , 0.4988  , 0.8     ],\n",
       "       [0.482   , 0.1667  , 0.6494  , 0.865   , 0.1674  , 0.6987  ],\n",
       "       [0.001793, 0.1243  , 0.1346  , 0.3516  , 0.1328  , 0.2273  ],\n",
       "       [0.4573  , 0.2075  , 0.6196  , 0.902   , 0.1625  , 0.6943  ]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dump['norm_bb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22260000000000002"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4968-0.2742"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4458"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7686-0.3228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_ckpt = torch.load(\"/science/image/nlp-datasets/emanuele/checkpoints/iglue/conversions/pretrain/uc2_checkpoint_200000.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.new_token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.embeddings.image_embeddings.weight', 'bert.embeddings.image_embeddings.bias', 'bert.embeddings.image_location_embeddings.weight', 'bert.embeddings.image_location_embeddings.bias', 'bert.embeddings.image_token_type_embeddings.weight', 'bert.embeddings.image_layer_norm.weight', 'bert.embeddings.image_layer_norm.bias', 'bert.embeddings.image_location_layer_norm.weight', 'bert.embeddings.image_location_layer_norm.bias', 'bert.embeddings.v_LayerNorm.weight', 'bert.embeddings.v_LayerNorm.bias', 'bert.encoder.layer.0.attention_self.query.weight', 'bert.encoder.layer.0.attention_self.query.bias', 'bert.encoder.layer.0.attention_self.key.weight', 'bert.encoder.layer.0.attention_self.key.bias', 'bert.encoder.layer.0.attention_self.value.weight', 'bert.encoder.layer.0.attention_self.value.bias', 'bert.encoder.layer.0.attention_self.v_query.weight', 'bert.encoder.layer.0.attention_self.v_query.bias', 'bert.encoder.layer.0.attention_self.v_key.weight', 'bert.encoder.layer.0.attention_self.v_key.bias', 'bert.encoder.layer.0.attention_self.v_value.weight', 'bert.encoder.layer.0.attention_self.v_value.bias', 'bert.encoder.layer.0.attention_output.dense.weight', 'bert.encoder.layer.0.attention_output.dense.bias', 'bert.encoder.layer.0.attention_output.LayerNorm.weight', 'bert.encoder.layer.0.attention_output.LayerNorm.bias', 'bert.encoder.layer.0.attention_output.v_dense.weight', 'bert.encoder.layer.0.attention_output.v_dense.bias', 'bert.encoder.layer.0.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.0.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.intermediate.v_dense.weight', 'bert.encoder.layer.1.intermediate.v_dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.output.v_dense.weight', 'bert.encoder.layer.1.output.v_dense.bias', 'bert.encoder.layer.1.output.v_LayerNorm.weight', 'bert.encoder.layer.1.output.v_LayerNorm.bias', 'bert.encoder.layer.2.attention_self.query.weight', 'bert.encoder.layer.2.attention_self.query.bias', 'bert.encoder.layer.2.attention_self.key.weight', 'bert.encoder.layer.2.attention_self.key.bias', 'bert.encoder.layer.2.attention_self.value.weight', 'bert.encoder.layer.2.attention_self.value.bias', 'bert.encoder.layer.2.attention_self.v_query.weight', 'bert.encoder.layer.2.attention_self.v_query.bias', 'bert.encoder.layer.2.attention_self.v_key.weight', 'bert.encoder.layer.2.attention_self.v_key.bias', 'bert.encoder.layer.2.attention_self.v_value.weight', 'bert.encoder.layer.2.attention_self.v_value.bias', 'bert.encoder.layer.2.attention_output.dense.weight', 'bert.encoder.layer.2.attention_output.dense.bias', 'bert.encoder.layer.2.attention_output.LayerNorm.weight', 'bert.encoder.layer.2.attention_output.LayerNorm.bias', 'bert.encoder.layer.2.attention_output.v_dense.weight', 'bert.encoder.layer.2.attention_output.v_dense.bias', 'bert.encoder.layer.2.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.2.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.intermediate.v_dense.weight', 'bert.encoder.layer.3.intermediate.v_dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.output.v_dense.weight', 'bert.encoder.layer.3.output.v_dense.bias', 'bert.encoder.layer.3.output.v_LayerNorm.weight', 'bert.encoder.layer.3.output.v_LayerNorm.bias', 'bert.encoder.layer.4.attention_self.query.weight', 'bert.encoder.layer.4.attention_self.query.bias', 'bert.encoder.layer.4.attention_self.key.weight', 'bert.encoder.layer.4.attention_self.key.bias', 'bert.encoder.layer.4.attention_self.value.weight', 'bert.encoder.layer.4.attention_self.value.bias', 'bert.encoder.layer.4.attention_self.v_query.weight', 'bert.encoder.layer.4.attention_self.v_query.bias', 'bert.encoder.layer.4.attention_self.v_key.weight', 'bert.encoder.layer.4.attention_self.v_key.bias', 'bert.encoder.layer.4.attention_self.v_value.weight', 'bert.encoder.layer.4.attention_self.v_value.bias', 'bert.encoder.layer.4.attention_output.dense.weight', 'bert.encoder.layer.4.attention_output.dense.bias', 'bert.encoder.layer.4.attention_output.LayerNorm.weight', 'bert.encoder.layer.4.attention_output.LayerNorm.bias', 'bert.encoder.layer.4.attention_output.v_dense.weight', 'bert.encoder.layer.4.attention_output.v_dense.bias', 'bert.encoder.layer.4.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.4.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.intermediate.v_dense.weight', 'bert.encoder.layer.5.intermediate.v_dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.output.v_dense.weight', 'bert.encoder.layer.5.output.v_dense.bias', 'bert.encoder.layer.5.output.v_LayerNorm.weight', 'bert.encoder.layer.5.output.v_LayerNorm.bias', 'bert.encoder.layer.6.attention_self.query.weight', 'bert.encoder.layer.6.attention_self.query.bias', 'bert.encoder.layer.6.attention_self.key.weight', 'bert.encoder.layer.6.attention_self.key.bias', 'bert.encoder.layer.6.attention_self.value.weight', 'bert.encoder.layer.6.attention_self.value.bias', 'bert.encoder.layer.6.attention_self.v_query.weight', 'bert.encoder.layer.6.attention_self.v_query.bias', 'bert.encoder.layer.6.attention_self.v_key.weight', 'bert.encoder.layer.6.attention_self.v_key.bias', 'bert.encoder.layer.6.attention_self.v_value.weight', 'bert.encoder.layer.6.attention_self.v_value.bias', 'bert.encoder.layer.6.attention_output.dense.weight', 'bert.encoder.layer.6.attention_output.dense.bias', 'bert.encoder.layer.6.attention_output.LayerNorm.weight', 'bert.encoder.layer.6.attention_output.LayerNorm.bias', 'bert.encoder.layer.6.attention_output.v_dense.weight', 'bert.encoder.layer.6.attention_output.v_dense.bias', 'bert.encoder.layer.6.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.6.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.v_dense.weight', 'bert.encoder.layer.7.intermediate.v_dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.output.v_dense.weight', 'bert.encoder.layer.7.output.v_dense.bias', 'bert.encoder.layer.7.output.v_LayerNorm.weight', 'bert.encoder.layer.7.output.v_LayerNorm.bias', 'bert.encoder.layer.8.attention_self.query.weight', 'bert.encoder.layer.8.attention_self.query.bias', 'bert.encoder.layer.8.attention_self.key.weight', 'bert.encoder.layer.8.attention_self.key.bias', 'bert.encoder.layer.8.attention_self.value.weight', 'bert.encoder.layer.8.attention_self.value.bias', 'bert.encoder.layer.8.attention_self.v_query.weight', 'bert.encoder.layer.8.attention_self.v_query.bias', 'bert.encoder.layer.8.attention_self.v_key.weight', 'bert.encoder.layer.8.attention_self.v_key.bias', 'bert.encoder.layer.8.attention_self.v_value.weight', 'bert.encoder.layer.8.attention_self.v_value.bias', 'bert.encoder.layer.8.attention_output.dense.weight', 'bert.encoder.layer.8.attention_output.dense.bias', 'bert.encoder.layer.8.attention_output.LayerNorm.weight', 'bert.encoder.layer.8.attention_output.LayerNorm.bias', 'bert.encoder.layer.8.attention_output.v_dense.weight', 'bert.encoder.layer.8.attention_output.v_dense.bias', 'bert.encoder.layer.8.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.8.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.intermediate.v_dense.weight', 'bert.encoder.layer.9.intermediate.v_dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.output.v_dense.weight', 'bert.encoder.layer.9.output.v_dense.bias', 'bert.encoder.layer.9.output.v_LayerNorm.weight', 'bert.encoder.layer.9.output.v_LayerNorm.bias', 'bert.encoder.layer.10.attention_self.query.weight', 'bert.encoder.layer.10.attention_self.query.bias', 'bert.encoder.layer.10.attention_self.key.weight', 'bert.encoder.layer.10.attention_self.key.bias', 'bert.encoder.layer.10.attention_self.value.weight', 'bert.encoder.layer.10.attention_self.value.bias', 'bert.encoder.layer.10.attention_self.v_query.weight', 'bert.encoder.layer.10.attention_self.v_query.bias', 'bert.encoder.layer.10.attention_self.v_key.weight', 'bert.encoder.layer.10.attention_self.v_key.bias', 'bert.encoder.layer.10.attention_self.v_value.weight', 'bert.encoder.layer.10.attention_self.v_value.bias', 'bert.encoder.layer.10.attention_output.dense.weight', 'bert.encoder.layer.10.attention_output.dense.bias', 'bert.encoder.layer.10.attention_output.LayerNorm.weight', 'bert.encoder.layer.10.attention_output.LayerNorm.bias', 'bert.encoder.layer.10.attention_output.v_dense.weight', 'bert.encoder.layer.10.attention_output.v_dense.bias', 'bert.encoder.layer.10.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.10.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.intermediate.v_dense.weight', 'bert.encoder.layer.11.intermediate.v_dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.output.v_dense.weight', 'bert.encoder.layer.11.output.v_dense.bias', 'bert.encoder.layer.11.output.v_LayerNorm.weight', 'bert.encoder.layer.11.output.v_LayerNorm.bias', 'bert.encoder.layer.12.attention_self.query.weight', 'bert.encoder.layer.12.attention_self.query.bias', 'bert.encoder.layer.12.attention_self.key.weight', 'bert.encoder.layer.12.attention_self.key.bias', 'bert.encoder.layer.12.attention_self.value.weight', 'bert.encoder.layer.12.attention_self.value.bias', 'bert.encoder.layer.12.attention_self.v_query.weight', 'bert.encoder.layer.12.attention_self.v_query.bias', 'bert.encoder.layer.12.attention_self.v_key.weight', 'bert.encoder.layer.12.attention_self.v_key.bias', 'bert.encoder.layer.12.attention_self.v_value.weight', 'bert.encoder.layer.12.attention_self.v_value.bias', 'bert.encoder.layer.12.attention_output.dense.weight', 'bert.encoder.layer.12.attention_output.dense.bias', 'bert.encoder.layer.12.attention_output.LayerNorm.weight', 'bert.encoder.layer.12.attention_output.LayerNorm.bias', 'bert.encoder.layer.12.attention_output.v_dense.weight', 'bert.encoder.layer.12.attention_output.v_dense.bias', 'bert.encoder.layer.12.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.12.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.13.intermediate.dense.weight', 'bert.encoder.layer.13.intermediate.dense.bias', 'bert.encoder.layer.13.intermediate.v_dense.weight', 'bert.encoder.layer.13.intermediate.v_dense.bias', 'bert.encoder.layer.13.output.dense.weight', 'bert.encoder.layer.13.output.dense.bias', 'bert.encoder.layer.13.output.LayerNorm.weight', 'bert.encoder.layer.13.output.LayerNorm.bias', 'bert.encoder.layer.13.output.v_dense.weight', 'bert.encoder.layer.13.output.v_dense.bias', 'bert.encoder.layer.13.output.v_LayerNorm.weight', 'bert.encoder.layer.13.output.v_LayerNorm.bias', 'bert.encoder.layer.14.attention_self.query.weight', 'bert.encoder.layer.14.attention_self.query.bias', 'bert.encoder.layer.14.attention_self.key.weight', 'bert.encoder.layer.14.attention_self.key.bias', 'bert.encoder.layer.14.attention_self.value.weight', 'bert.encoder.layer.14.attention_self.value.bias', 'bert.encoder.layer.14.attention_self.v_query.weight', 'bert.encoder.layer.14.attention_self.v_query.bias', 'bert.encoder.layer.14.attention_self.v_key.weight', 'bert.encoder.layer.14.attention_self.v_key.bias', 'bert.encoder.layer.14.attention_self.v_value.weight', 'bert.encoder.layer.14.attention_self.v_value.bias', 'bert.encoder.layer.14.attention_output.dense.weight', 'bert.encoder.layer.14.attention_output.dense.bias', 'bert.encoder.layer.14.attention_output.LayerNorm.weight', 'bert.encoder.layer.14.attention_output.LayerNorm.bias', 'bert.encoder.layer.14.attention_output.v_dense.weight', 'bert.encoder.layer.14.attention_output.v_dense.bias', 'bert.encoder.layer.14.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.14.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.15.intermediate.dense.weight', 'bert.encoder.layer.15.intermediate.dense.bias', 'bert.encoder.layer.15.intermediate.v_dense.weight', 'bert.encoder.layer.15.intermediate.v_dense.bias', 'bert.encoder.layer.15.output.dense.weight', 'bert.encoder.layer.15.output.dense.bias', 'bert.encoder.layer.15.output.LayerNorm.weight', 'bert.encoder.layer.15.output.LayerNorm.bias', 'bert.encoder.layer.15.output.v_dense.weight', 'bert.encoder.layer.15.output.v_dense.bias', 'bert.encoder.layer.15.output.v_LayerNorm.weight', 'bert.encoder.layer.15.output.v_LayerNorm.bias', 'bert.encoder.layer.16.attention_self.query.weight', 'bert.encoder.layer.16.attention_self.query.bias', 'bert.encoder.layer.16.attention_self.key.weight', 'bert.encoder.layer.16.attention_self.key.bias', 'bert.encoder.layer.16.attention_self.value.weight', 'bert.encoder.layer.16.attention_self.value.bias', 'bert.encoder.layer.16.attention_self.v_query.weight', 'bert.encoder.layer.16.attention_self.v_query.bias', 'bert.encoder.layer.16.attention_self.v_key.weight', 'bert.encoder.layer.16.attention_self.v_key.bias', 'bert.encoder.layer.16.attention_self.v_value.weight', 'bert.encoder.layer.16.attention_self.v_value.bias', 'bert.encoder.layer.16.attention_output.dense.weight', 'bert.encoder.layer.16.attention_output.dense.bias', 'bert.encoder.layer.16.attention_output.LayerNorm.weight', 'bert.encoder.layer.16.attention_output.LayerNorm.bias', 'bert.encoder.layer.16.attention_output.v_dense.weight', 'bert.encoder.layer.16.attention_output.v_dense.bias', 'bert.encoder.layer.16.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.16.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.17.intermediate.dense.weight', 'bert.encoder.layer.17.intermediate.dense.bias', 'bert.encoder.layer.17.intermediate.v_dense.weight', 'bert.encoder.layer.17.intermediate.v_dense.bias', 'bert.encoder.layer.17.output.dense.weight', 'bert.encoder.layer.17.output.dense.bias', 'bert.encoder.layer.17.output.LayerNorm.weight', 'bert.encoder.layer.17.output.LayerNorm.bias', 'bert.encoder.layer.17.output.v_dense.weight', 'bert.encoder.layer.17.output.v_dense.bias', 'bert.encoder.layer.17.output.v_LayerNorm.weight', 'bert.encoder.layer.17.output.v_LayerNorm.bias', 'bert.encoder.layer.18.attention_self.query.weight', 'bert.encoder.layer.18.attention_self.query.bias', 'bert.encoder.layer.18.attention_self.key.weight', 'bert.encoder.layer.18.attention_self.key.bias', 'bert.encoder.layer.18.attention_self.value.weight', 'bert.encoder.layer.18.attention_self.value.bias', 'bert.encoder.layer.18.attention_self.v_query.weight', 'bert.encoder.layer.18.attention_self.v_query.bias', 'bert.encoder.layer.18.attention_self.v_key.weight', 'bert.encoder.layer.18.attention_self.v_key.bias', 'bert.encoder.layer.18.attention_self.v_value.weight', 'bert.encoder.layer.18.attention_self.v_value.bias', 'bert.encoder.layer.18.attention_output.dense.weight', 'bert.encoder.layer.18.attention_output.dense.bias', 'bert.encoder.layer.18.attention_output.LayerNorm.weight', 'bert.encoder.layer.18.attention_output.LayerNorm.bias', 'bert.encoder.layer.18.attention_output.v_dense.weight', 'bert.encoder.layer.18.attention_output.v_dense.bias', 'bert.encoder.layer.18.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.18.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.19.intermediate.dense.weight', 'bert.encoder.layer.19.intermediate.dense.bias', 'bert.encoder.layer.19.intermediate.v_dense.weight', 'bert.encoder.layer.19.intermediate.v_dense.bias', 'bert.encoder.layer.19.output.dense.weight', 'bert.encoder.layer.19.output.dense.bias', 'bert.encoder.layer.19.output.LayerNorm.weight', 'bert.encoder.layer.19.output.LayerNorm.bias', 'bert.encoder.layer.19.output.v_dense.weight', 'bert.encoder.layer.19.output.v_dense.bias', 'bert.encoder.layer.19.output.v_LayerNorm.weight', 'bert.encoder.layer.19.output.v_LayerNorm.bias', 'bert.encoder.layer.20.attention_self.query.weight', 'bert.encoder.layer.20.attention_self.query.bias', 'bert.encoder.layer.20.attention_self.key.weight', 'bert.encoder.layer.20.attention_self.key.bias', 'bert.encoder.layer.20.attention_self.value.weight', 'bert.encoder.layer.20.attention_self.value.bias', 'bert.encoder.layer.20.attention_self.v_query.weight', 'bert.encoder.layer.20.attention_self.v_query.bias', 'bert.encoder.layer.20.attention_self.v_key.weight', 'bert.encoder.layer.20.attention_self.v_key.bias', 'bert.encoder.layer.20.attention_self.v_value.weight', 'bert.encoder.layer.20.attention_self.v_value.bias', 'bert.encoder.layer.20.attention_output.dense.weight', 'bert.encoder.layer.20.attention_output.dense.bias', 'bert.encoder.layer.20.attention_output.LayerNorm.weight', 'bert.encoder.layer.20.attention_output.LayerNorm.bias', 'bert.encoder.layer.20.attention_output.v_dense.weight', 'bert.encoder.layer.20.attention_output.v_dense.bias', 'bert.encoder.layer.20.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.20.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.21.intermediate.dense.weight', 'bert.encoder.layer.21.intermediate.dense.bias', 'bert.encoder.layer.21.intermediate.v_dense.weight', 'bert.encoder.layer.21.intermediate.v_dense.bias', 'bert.encoder.layer.21.output.dense.weight', 'bert.encoder.layer.21.output.dense.bias', 'bert.encoder.layer.21.output.LayerNorm.weight', 'bert.encoder.layer.21.output.LayerNorm.bias', 'bert.encoder.layer.21.output.v_dense.weight', 'bert.encoder.layer.21.output.v_dense.bias', 'bert.encoder.layer.21.output.v_LayerNorm.weight', 'bert.encoder.layer.21.output.v_LayerNorm.bias', 'bert.encoder.layer.22.attention_self.query.weight', 'bert.encoder.layer.22.attention_self.query.bias', 'bert.encoder.layer.22.attention_self.key.weight', 'bert.encoder.layer.22.attention_self.key.bias', 'bert.encoder.layer.22.attention_self.value.weight', 'bert.encoder.layer.22.attention_self.value.bias', 'bert.encoder.layer.22.attention_self.v_query.weight', 'bert.encoder.layer.22.attention_self.v_query.bias', 'bert.encoder.layer.22.attention_self.v_key.weight', 'bert.encoder.layer.22.attention_self.v_key.bias', 'bert.encoder.layer.22.attention_self.v_value.weight', 'bert.encoder.layer.22.attention_self.v_value.bias', 'bert.encoder.layer.22.attention_output.dense.weight', 'bert.encoder.layer.22.attention_output.dense.bias', 'bert.encoder.layer.22.attention_output.LayerNorm.weight', 'bert.encoder.layer.22.attention_output.LayerNorm.bias', 'bert.encoder.layer.22.attention_output.v_dense.weight', 'bert.encoder.layer.22.attention_output.v_dense.bias', 'bert.encoder.layer.22.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.22.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.23.intermediate.dense.weight', 'bert.encoder.layer.23.intermediate.dense.bias', 'bert.encoder.layer.23.intermediate.v_dense.weight', 'bert.encoder.layer.23.intermediate.v_dense.bias', 'bert.encoder.layer.23.output.dense.weight', 'bert.encoder.layer.23.output.dense.bias', 'bert.encoder.layer.23.output.LayerNorm.weight', 'bert.encoder.layer.23.output.LayerNorm.bias', 'bert.encoder.layer.23.output.v_dense.weight', 'bert.encoder.layer.23.output.v_dense.bias', 'bert.encoder.layer.23.output.v_LayerNorm.weight', 'bert.encoder.layer.23.output.v_LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.t_pooler.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0035,  0.0005, -0.0106,  ...,  0.0034, -0.0266,  0.0057],\n",
       "        [-0.0038,  0.0116, -0.0085,  ..., -0.0195,  0.0108,  0.0071]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_ckpt['cls.bi_seq_relationship.weight'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "\n",
    "with open(config_file) as data_file:\n",
    "    arguments = json.load(data_file)\n",
    "# arguments\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"title\", formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "for key, val in arguments.items():\n",
    "    setattr(parser, key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc2 = torch.load(\"UC2_DATA/pretrain/uc2/ckpt/model_step_200000.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'object_labels/img_label_objects.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-fed2956dfaed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UC2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVLXLMRForImageTextRetrieval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# opts = parser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/iglue/volta/conversions/UC2/model/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUniterForPretraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUniterConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVLXLMRForPretraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvqa\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUniterForVisualQuestionAnswering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVLXLMRForVisualQuestionAnswering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m from .nlvr2 import (UniterForNlvr2PairedAttn, UniterForNlvr2Paired,\n\u001b[1;32m      4\u001b[0m                     UniterForNlvr2Triplet)\n\u001b[1;32m      5\u001b[0m from .itm import (UniterForImageTextRetrieval,\n",
      "\u001b[0;32m~/projects/iglue/volta/conversions/UC2/model/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGELU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertPooler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertOnlyMLMHead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRobertaLMHead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVisualRobertaLMHead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimal_transport_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconst_variable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXLMR_TOKER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABEL2TOKEN_MATRIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVALID_XLMR_TOKEN_IDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#     LABEL2TOKEN_MATRIX = torch.cuda.HalfTensor(LABEL2TOKEN_MATRIX)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/iglue/volta/conversions/UC2/model/const_variable.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Load the XLMR_TOKER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mXLMR_TOKER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXLMRobertaTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xlm-roberta-base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object_labels/img_label_objects.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mIMG_LABEL_OBJECTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mIMG_LABEL_OBJECTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'background'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mIMG_LABEL_OBJECTS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'object_labels/img_label_objects.txt'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"UC2\")\n",
    "from model import VLXLMRForImageTextRetrieval\n",
    "\n",
    "# opts = parser\n",
    "# model = VLXLMRForImageTextRetrieval.from_pretrained(\n",
    "#     opts.model_config, \n",
    "#     state_dict=uc2,\n",
    "#     load_embedding_only=opts.load_embedding_only,\n",
    "#     load_layer=opts.load_layer,\n",
    "#     img_dim=IMG_DIM, \n",
    "#     margin=opts.margin\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mc-bert",
   "language": "python",
   "name": "mc-bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
