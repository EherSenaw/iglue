{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ckpt conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"/science/image/nlp-datasets/emanuele/checkpoints/M3P/checkpoint.pth\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'n_total_iter', 'best_metrics', 'best_stopping_criterion', 'model', 'model_optimizer', 'params'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['params']['gelu_activation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ckpt['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['module.position_embeddings.weight', 'module.cross_lang_embeddings.weight', 'module.embeddings.weight', 'module.layer_norm_emb.weight', 'module.layer_norm_emb.bias', 'module.image_embeddings.image_embeddings.weight', 'module.image_embeddings.image_embeddings.bias', 'module.image_embeddings.image_distbution_embeddings.weight', 'module.image_embeddings.image_distbution_embeddings.bias', 'module.image_embeddings.image_location_embeddings.weight', 'module.image_embeddings.image_location_embeddings.bias', 'module.image_embeddings.LayerNorm.weight', 'module.image_embeddings.LayerNorm.bias', 'module.refine_embeddings.layers.0.self_attn.linears.0.weight', 'module.refine_embeddings.layers.0.self_attn.linears.0.bias', 'module.refine_embeddings.layers.0.self_attn.linears.1.weight', 'module.refine_embeddings.layers.0.self_attn.linears.1.bias', 'module.refine_embeddings.layers.0.self_attn.linears.2.weight', 'module.refine_embeddings.layers.0.self_attn.linears.2.bias', 'module.refine_embeddings.layers.0.self_attn.aoa_layer.0.weight', 'module.refine_embeddings.layers.0.self_attn.aoa_layer.0.bias', 'module.refine_embeddings.layers.0.feed_forward.lin1.weight', 'module.refine_embeddings.layers.0.feed_forward.lin1.bias', 'module.refine_embeddings.layers.0.feed_forward.lin2.weight', 'module.refine_embeddings.layers.0.feed_forward.lin2.bias', 'module.refine_embeddings.layers.0.sublayer.0.norm.weight', 'module.refine_embeddings.layers.0.sublayer.0.norm.bias', 'module.refine_embeddings.layers.0.sublayer.1.norm.weight', 'module.refine_embeddings.layers.0.sublayer.1.norm.bias', 'module.refine_embeddings.layers.1.self_attn.linears.0.weight', 'module.refine_embeddings.layers.1.self_attn.linears.0.bias', 'module.refine_embeddings.layers.1.self_attn.linears.1.weight', 'module.refine_embeddings.layers.1.self_attn.linears.1.bias', 'module.refine_embeddings.layers.1.self_attn.linears.2.weight', 'module.refine_embeddings.layers.1.self_attn.linears.2.bias', 'module.refine_embeddings.layers.1.self_attn.aoa_layer.0.weight', 'module.refine_embeddings.layers.1.self_attn.aoa_layer.0.bias', 'module.refine_embeddings.layers.1.feed_forward.lin1.weight', 'module.refine_embeddings.layers.1.feed_forward.lin1.bias', 'module.refine_embeddings.layers.1.feed_forward.lin2.weight', 'module.refine_embeddings.layers.1.feed_forward.lin2.bias', 'module.refine_embeddings.layers.1.sublayer.0.norm.weight', 'module.refine_embeddings.layers.1.sublayer.0.norm.bias', 'module.refine_embeddings.layers.1.sublayer.1.norm.weight', 'module.refine_embeddings.layers.1.sublayer.1.norm.bias', 'module.refine_embeddings.layers.2.self_attn.linears.0.weight', 'module.refine_embeddings.layers.2.self_attn.linears.0.bias', 'module.refine_embeddings.layers.2.self_attn.linears.1.weight', 'module.refine_embeddings.layers.2.self_attn.linears.1.bias', 'module.refine_embeddings.layers.2.self_attn.linears.2.weight', 'module.refine_embeddings.layers.2.self_attn.linears.2.bias', 'module.refine_embeddings.layers.2.self_attn.aoa_layer.0.weight', 'module.refine_embeddings.layers.2.self_attn.aoa_layer.0.bias', 'module.refine_embeddings.layers.2.feed_forward.lin1.weight', 'module.refine_embeddings.layers.2.feed_forward.lin1.bias', 'module.refine_embeddings.layers.2.feed_forward.lin2.weight', 'module.refine_embeddings.layers.2.feed_forward.lin2.bias', 'module.refine_embeddings.layers.2.sublayer.0.norm.weight', 'module.refine_embeddings.layers.2.sublayer.0.norm.bias', 'module.refine_embeddings.layers.2.sublayer.1.norm.weight', 'module.refine_embeddings.layers.2.sublayer.1.norm.bias', 'module.refine_embeddings.layers.3.self_attn.linears.0.weight', 'module.refine_embeddings.layers.3.self_attn.linears.0.bias', 'module.refine_embeddings.layers.3.self_attn.linears.1.weight', 'module.refine_embeddings.layers.3.self_attn.linears.1.bias', 'module.refine_embeddings.layers.3.self_attn.linears.2.weight', 'module.refine_embeddings.layers.3.self_attn.linears.2.bias', 'module.refine_embeddings.layers.3.self_attn.aoa_layer.0.weight', 'module.refine_embeddings.layers.3.self_attn.aoa_layer.0.bias', 'module.refine_embeddings.layers.3.feed_forward.lin1.weight', 'module.refine_embeddings.layers.3.feed_forward.lin1.bias', 'module.refine_embeddings.layers.3.feed_forward.lin2.weight', 'module.refine_embeddings.layers.3.feed_forward.lin2.bias', 'module.refine_embeddings.layers.3.sublayer.0.norm.weight', 'module.refine_embeddings.layers.3.sublayer.0.norm.bias', 'module.refine_embeddings.layers.3.sublayer.1.norm.weight', 'module.refine_embeddings.layers.3.sublayer.1.norm.bias', 'module.refine_embeddings.layers.4.self_attn.linears.0.weight', 'module.refine_embeddings.layers.4.self_attn.linears.0.bias', 'module.refine_embeddings.layers.4.self_attn.linears.1.weight', 'module.refine_embeddings.layers.4.self_attn.linears.1.bias', 'module.refine_embeddings.layers.4.self_attn.linears.2.weight', 'module.refine_embeddings.layers.4.self_attn.linears.2.bias', 'module.refine_embeddings.layers.4.self_attn.aoa_layer.0.weight', 'module.refine_embeddings.layers.4.self_attn.aoa_layer.0.bias', 'module.refine_embeddings.layers.4.feed_forward.lin1.weight', 'module.refine_embeddings.layers.4.feed_forward.lin1.bias', 'module.refine_embeddings.layers.4.feed_forward.lin2.weight', 'module.refine_embeddings.layers.4.feed_forward.lin2.bias', 'module.refine_embeddings.layers.4.sublayer.0.norm.weight', 'module.refine_embeddings.layers.4.sublayer.0.norm.bias', 'module.refine_embeddings.layers.4.sublayer.1.norm.weight', 'module.refine_embeddings.layers.4.sublayer.1.norm.bias', 'module.refine_embeddings.layers.5.self_attn.linears.0.weight', 'module.refine_embeddings.layers.5.self_attn.linears.0.bias', 'module.refine_embeddings.layers.5.self_attn.linears.1.weight', 'module.refine_embeddings.layers.5.self_attn.linears.1.bias', 'module.refine_embeddings.layers.5.self_attn.linears.2.weight', 'module.refine_embeddings.layers.5.self_attn.linears.2.bias', 'module.refine_embeddings.layers.5.self_attn.aoa_layer.0.weight', 'module.refine_embeddings.layers.5.self_attn.aoa_layer.0.bias', 'module.refine_embeddings.layers.5.feed_forward.lin1.weight', 'module.refine_embeddings.layers.5.feed_forward.lin1.bias', 'module.refine_embeddings.layers.5.feed_forward.lin2.weight', 'module.refine_embeddings.layers.5.feed_forward.lin2.bias', 'module.refine_embeddings.layers.5.sublayer.0.norm.weight', 'module.refine_embeddings.layers.5.sublayer.0.norm.bias', 'module.refine_embeddings.layers.5.sublayer.1.norm.weight', 'module.refine_embeddings.layers.5.sublayer.1.norm.bias', 'module.refine_embeddings.norm.weight', 'module.refine_embeddings.norm.bias', 'module.cross_alignment.att_weight_c.weight', 'module.cross_alignment.att_weight_c.bias', 'module.cross_alignment.att_weight_q.weight', 'module.cross_alignment.att_weight_q.bias', 'module.cross_alignment.att_weight_cq.weight', 'module.cross_alignment.att_weight_cq.bias', 'module.cross_alignment.align_output.weight', 'module.cross_alignment.align_output.bias', 'module.cross_alignment.layer_norm.weight', 'module.cross_alignment.layer_norm.bias', 'module.attentions.0.q_lin.weight', 'module.attentions.0.q_lin.bias', 'module.attentions.0.k_lin.weight', 'module.attentions.0.k_lin.bias', 'module.attentions.0.v_lin.weight', 'module.attentions.0.v_lin.bias', 'module.attentions.0.out_lin.weight', 'module.attentions.0.out_lin.bias', 'module.attentions.1.q_lin.weight', 'module.attentions.1.q_lin.bias', 'module.attentions.1.k_lin.weight', 'module.attentions.1.k_lin.bias', 'module.attentions.1.v_lin.weight', 'module.attentions.1.v_lin.bias', 'module.attentions.1.out_lin.weight', 'module.attentions.1.out_lin.bias', 'module.attentions.2.q_lin.weight', 'module.attentions.2.q_lin.bias', 'module.attentions.2.k_lin.weight', 'module.attentions.2.k_lin.bias', 'module.attentions.2.v_lin.weight', 'module.attentions.2.v_lin.bias', 'module.attentions.2.out_lin.weight', 'module.attentions.2.out_lin.bias', 'module.attentions.3.q_lin.weight', 'module.attentions.3.q_lin.bias', 'module.attentions.3.k_lin.weight', 'module.attentions.3.k_lin.bias', 'module.attentions.3.v_lin.weight', 'module.attentions.3.v_lin.bias', 'module.attentions.3.out_lin.weight', 'module.attentions.3.out_lin.bias', 'module.attentions.4.q_lin.weight', 'module.attentions.4.q_lin.bias', 'module.attentions.4.k_lin.weight', 'module.attentions.4.k_lin.bias', 'module.attentions.4.v_lin.weight', 'module.attentions.4.v_lin.bias', 'module.attentions.4.out_lin.weight', 'module.attentions.4.out_lin.bias', 'module.attentions.5.q_lin.weight', 'module.attentions.5.q_lin.bias', 'module.attentions.5.k_lin.weight', 'module.attentions.5.k_lin.bias', 'module.attentions.5.v_lin.weight', 'module.attentions.5.v_lin.bias', 'module.attentions.5.out_lin.weight', 'module.attentions.5.out_lin.bias', 'module.attentions.6.q_lin.weight', 'module.attentions.6.q_lin.bias', 'module.attentions.6.k_lin.weight', 'module.attentions.6.k_lin.bias', 'module.attentions.6.v_lin.weight', 'module.attentions.6.v_lin.bias', 'module.attentions.6.out_lin.weight', 'module.attentions.6.out_lin.bias', 'module.attentions.7.q_lin.weight', 'module.attentions.7.q_lin.bias', 'module.attentions.7.k_lin.weight', 'module.attentions.7.k_lin.bias', 'module.attentions.7.v_lin.weight', 'module.attentions.7.v_lin.bias', 'module.attentions.7.out_lin.weight', 'module.attentions.7.out_lin.bias', 'module.attentions.8.q_lin.weight', 'module.attentions.8.q_lin.bias', 'module.attentions.8.k_lin.weight', 'module.attentions.8.k_lin.bias', 'module.attentions.8.v_lin.weight', 'module.attentions.8.v_lin.bias', 'module.attentions.8.out_lin.weight', 'module.attentions.8.out_lin.bias', 'module.attentions.9.q_lin.weight', 'module.attentions.9.q_lin.bias', 'module.attentions.9.k_lin.weight', 'module.attentions.9.k_lin.bias', 'module.attentions.9.v_lin.weight', 'module.attentions.9.v_lin.bias', 'module.attentions.9.out_lin.weight', 'module.attentions.9.out_lin.bias', 'module.attentions.10.q_lin.weight', 'module.attentions.10.q_lin.bias', 'module.attentions.10.k_lin.weight', 'module.attentions.10.k_lin.bias', 'module.attentions.10.v_lin.weight', 'module.attentions.10.v_lin.bias', 'module.attentions.10.out_lin.weight', 'module.attentions.10.out_lin.bias', 'module.attentions.11.q_lin.weight', 'module.attentions.11.q_lin.bias', 'module.attentions.11.k_lin.weight', 'module.attentions.11.k_lin.bias', 'module.attentions.11.v_lin.weight', 'module.attentions.11.v_lin.bias', 'module.attentions.11.out_lin.weight', 'module.attentions.11.out_lin.bias', 'module.layer_norm1.0.weight', 'module.layer_norm1.0.bias', 'module.layer_norm1.1.weight', 'module.layer_norm1.1.bias', 'module.layer_norm1.2.weight', 'module.layer_norm1.2.bias', 'module.layer_norm1.3.weight', 'module.layer_norm1.3.bias', 'module.layer_norm1.4.weight', 'module.layer_norm1.4.bias', 'module.layer_norm1.5.weight', 'module.layer_norm1.5.bias', 'module.layer_norm1.6.weight', 'module.layer_norm1.6.bias', 'module.layer_norm1.7.weight', 'module.layer_norm1.7.bias', 'module.layer_norm1.8.weight', 'module.layer_norm1.8.bias', 'module.layer_norm1.9.weight', 'module.layer_norm1.9.bias', 'module.layer_norm1.10.weight', 'module.layer_norm1.10.bias', 'module.layer_norm1.11.weight', 'module.layer_norm1.11.bias', 'module.ffns.0.lin1.weight', 'module.ffns.0.lin1.bias', 'module.ffns.0.lin2.weight', 'module.ffns.0.lin2.bias', 'module.ffns.1.lin1.weight', 'module.ffns.1.lin1.bias', 'module.ffns.1.lin2.weight', 'module.ffns.1.lin2.bias', 'module.ffns.2.lin1.weight', 'module.ffns.2.lin1.bias', 'module.ffns.2.lin2.weight', 'module.ffns.2.lin2.bias', 'module.ffns.3.lin1.weight', 'module.ffns.3.lin1.bias', 'module.ffns.3.lin2.weight', 'module.ffns.3.lin2.bias', 'module.ffns.4.lin1.weight', 'module.ffns.4.lin1.bias', 'module.ffns.4.lin2.weight', 'module.ffns.4.lin2.bias', 'module.ffns.5.lin1.weight', 'module.ffns.5.lin1.bias', 'module.ffns.5.lin2.weight', 'module.ffns.5.lin2.bias', 'module.ffns.6.lin1.weight', 'module.ffns.6.lin1.bias', 'module.ffns.6.lin2.weight', 'module.ffns.6.lin2.bias', 'module.ffns.7.lin1.weight', 'module.ffns.7.lin1.bias', 'module.ffns.7.lin2.weight', 'module.ffns.7.lin2.bias', 'module.ffns.8.lin1.weight', 'module.ffns.8.lin1.bias', 'module.ffns.8.lin2.weight', 'module.ffns.8.lin2.bias', 'module.ffns.9.lin1.weight', 'module.ffns.9.lin1.bias', 'module.ffns.9.lin2.weight', 'module.ffns.9.lin2.bias', 'module.ffns.10.lin1.weight', 'module.ffns.10.lin1.bias', 'module.ffns.10.lin2.weight', 'module.ffns.10.lin2.bias', 'module.ffns.11.lin1.weight', 'module.ffns.11.lin1.bias', 'module.ffns.11.lin2.weight', 'module.ffns.11.lin2.bias', 'module.layer_norm2.0.weight', 'module.layer_norm2.0.bias', 'module.layer_norm2.1.weight', 'module.layer_norm2.1.bias', 'module.layer_norm2.2.weight', 'module.layer_norm2.2.bias', 'module.layer_norm2.3.weight', 'module.layer_norm2.3.bias', 'module.layer_norm2.4.weight', 'module.layer_norm2.4.bias', 'module.layer_norm2.5.weight', 'module.layer_norm2.5.bias', 'module.layer_norm2.6.weight', 'module.layer_norm2.6.bias', 'module.layer_norm2.7.weight', 'module.layer_norm2.7.bias', 'module.layer_norm2.8.weight', 'module.layer_norm2.8.bias', 'module.layer_norm2.9.weight', 'module.layer_norm2.9.bias', 'module.layer_norm2.10.weight', 'module.layer_norm2.10.bias', 'module.layer_norm2.11.weight', 'module.layer_norm2.11.bias', 'module.layer_norm15.0.weight', 'module.layer_norm15.0.bias', 'module.layer_norm15.1.weight', 'module.layer_norm15.1.bias', 'module.layer_norm15.2.weight', 'module.layer_norm15.2.bias', 'module.layer_norm15.3.weight', 'module.layer_norm15.3.bias', 'module.layer_norm15.4.weight', 'module.layer_norm15.4.bias', 'module.layer_norm15.5.weight', 'module.layer_norm15.5.bias', 'module.layer_norm15.6.weight', 'module.layer_norm15.6.bias', 'module.layer_norm15.7.weight', 'module.layer_norm15.7.bias', 'module.layer_norm15.8.weight', 'module.layer_norm15.8.bias', 'module.layer_norm15.9.weight', 'module.layer_norm15.9.bias', 'module.layer_norm15.10.weight', 'module.layer_norm15.10.bias', 'module.layer_norm15.11.weight', 'module.layer_norm15.11.bias', 'module.encoder_attn.0.q_lin.weight', 'module.encoder_attn.0.q_lin.bias', 'module.encoder_attn.0.k_lin.weight', 'module.encoder_attn.0.k_lin.bias', 'module.encoder_attn.0.v_lin.weight', 'module.encoder_attn.0.v_lin.bias', 'module.encoder_attn.0.out_lin.weight', 'module.encoder_attn.0.out_lin.bias', 'module.encoder_attn.1.q_lin.weight', 'module.encoder_attn.1.q_lin.bias', 'module.encoder_attn.1.k_lin.weight', 'module.encoder_attn.1.k_lin.bias', 'module.encoder_attn.1.v_lin.weight', 'module.encoder_attn.1.v_lin.bias', 'module.encoder_attn.1.out_lin.weight', 'module.encoder_attn.1.out_lin.bias', 'module.encoder_attn.2.q_lin.weight', 'module.encoder_attn.2.q_lin.bias', 'module.encoder_attn.2.k_lin.weight', 'module.encoder_attn.2.k_lin.bias', 'module.encoder_attn.2.v_lin.weight', 'module.encoder_attn.2.v_lin.bias', 'module.encoder_attn.2.out_lin.weight', 'module.encoder_attn.2.out_lin.bias', 'module.encoder_attn.3.q_lin.weight', 'module.encoder_attn.3.q_lin.bias', 'module.encoder_attn.3.k_lin.weight', 'module.encoder_attn.3.k_lin.bias', 'module.encoder_attn.3.v_lin.weight', 'module.encoder_attn.3.v_lin.bias', 'module.encoder_attn.3.out_lin.weight', 'module.encoder_attn.3.out_lin.bias', 'module.encoder_attn.4.q_lin.weight', 'module.encoder_attn.4.q_lin.bias', 'module.encoder_attn.4.k_lin.weight', 'module.encoder_attn.4.k_lin.bias', 'module.encoder_attn.4.v_lin.weight', 'module.encoder_attn.4.v_lin.bias', 'module.encoder_attn.4.out_lin.weight', 'module.encoder_attn.4.out_lin.bias', 'module.encoder_attn.5.q_lin.weight', 'module.encoder_attn.5.q_lin.bias', 'module.encoder_attn.5.k_lin.weight', 'module.encoder_attn.5.k_lin.bias', 'module.encoder_attn.5.v_lin.weight', 'module.encoder_attn.5.v_lin.bias', 'module.encoder_attn.5.out_lin.weight', 'module.encoder_attn.5.out_lin.bias', 'module.encoder_attn.6.q_lin.weight', 'module.encoder_attn.6.q_lin.bias', 'module.encoder_attn.6.k_lin.weight', 'module.encoder_attn.6.k_lin.bias', 'module.encoder_attn.6.v_lin.weight', 'module.encoder_attn.6.v_lin.bias', 'module.encoder_attn.6.out_lin.weight', 'module.encoder_attn.6.out_lin.bias', 'module.encoder_attn.7.q_lin.weight', 'module.encoder_attn.7.q_lin.bias', 'module.encoder_attn.7.k_lin.weight', 'module.encoder_attn.7.k_lin.bias', 'module.encoder_attn.7.v_lin.weight', 'module.encoder_attn.7.v_lin.bias', 'module.encoder_attn.7.out_lin.weight', 'module.encoder_attn.7.out_lin.bias', 'module.encoder_attn.8.q_lin.weight', 'module.encoder_attn.8.q_lin.bias', 'module.encoder_attn.8.k_lin.weight', 'module.encoder_attn.8.k_lin.bias', 'module.encoder_attn.8.v_lin.weight', 'module.encoder_attn.8.v_lin.bias', 'module.encoder_attn.8.out_lin.weight', 'module.encoder_attn.8.out_lin.bias', 'module.encoder_attn.9.q_lin.weight', 'module.encoder_attn.9.q_lin.bias', 'module.encoder_attn.9.k_lin.weight', 'module.encoder_attn.9.k_lin.bias', 'module.encoder_attn.9.v_lin.weight', 'module.encoder_attn.9.v_lin.bias', 'module.encoder_attn.9.out_lin.weight', 'module.encoder_attn.9.out_lin.bias', 'module.encoder_attn.10.q_lin.weight', 'module.encoder_attn.10.q_lin.bias', 'module.encoder_attn.10.k_lin.weight', 'module.encoder_attn.10.k_lin.bias', 'module.encoder_attn.10.v_lin.weight', 'module.encoder_attn.10.v_lin.bias', 'module.encoder_attn.10.out_lin.weight', 'module.encoder_attn.10.out_lin.bias', 'module.encoder_attn.11.q_lin.weight', 'module.encoder_attn.11.q_lin.bias', 'module.encoder_attn.11.k_lin.weight', 'module.encoder_attn.11.k_lin.bias', 'module.encoder_attn.11.v_lin.weight', 'module.encoder_attn.11.v_lin.bias', 'module.encoder_attn.11.out_lin.weight', 'module.encoder_attn.11.out_lin.bias', 'module.latent_transforms.0.x_to_mu.weight', 'module.latent_transforms.0.x_to_mu.bias', 'module.latent_transforms.0.x_to_logvar.weight', 'module.latent_transforms.0.x_to_logvar.bias', 'module.latent_transforms.0.out_dense.weight', 'module.latent_transforms.0.out_dense.bias', 'module.latent_transforms.1.x_to_mu.weight', 'module.latent_transforms.1.x_to_mu.bias', 'module.latent_transforms.1.x_to_logvar.weight', 'module.latent_transforms.1.x_to_logvar.bias', 'module.latent_transforms.1.out_dense.weight', 'module.latent_transforms.1.out_dense.bias', 'module.original_transforms.0.dense.weight', 'module.original_transforms.0.dense.bias', 'module.original_transforms.0.dense_mu.weight', 'module.original_transforms.0.dense_mu.bias', 'module.original_transforms.0.LayerNorm.weight', 'module.original_transforms.0.LayerNorm.bias', 'module.original_transforms.1.dense.weight', 'module.original_transforms.1.dense.bias', 'module.original_transforms.1.dense_mu.weight', 'module.original_transforms.1.dense_mu.bias', 'module.original_transforms.1.LayerNorm.weight', 'module.original_transforms.1.LayerNorm.bias', 'module.pooled_layer.dense.weight', 'module.pooled_layer.dense.bias', 'module.seq_relationship.weight', 'module.seq_relationship.bias', 'module.pooled_layer2.dense.weight', 'module.pooled_layer2.dense.bias', 'module.seq_relationship2.weight', 'module.seq_relationship2.bias', 'module.mrfr_dense.weight', 'module.mrfr_dense.bias', 'module.transformer_obj.dense.weight', 'module.transformer_obj.dense.bias', 'module.transformer_obj.LayerNorm.weight', 'module.transformer_obj.LayerNorm.bias', 'module.pred_layer.proj.weight', 'module.pred_layer.proj.bias', 'module.pred_obj_layer.proj.weight', 'module.pred_obj_layer.proj.bias'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ckpt\n",
    "old_keys = []\n",
    "new_keys = []\n",
    "for key in model.keys():\n",
    "    new_key = key.replace(\"module.\", \"bert.encoder.\")\n",
    "    old_keys.append(key)\n",
    "    new_keys.append(new_key)\n",
    "for old_key, new_key in zip(old_keys, new_keys):\n",
    "    model[new_key] = model.pop(old_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['bert.encoder.position_embeddings.weight', 'bert.encoder.cross_lang_embeddings.weight', 'bert.encoder.embeddings.weight', 'bert.encoder.layer_norm_emb.weight', 'bert.encoder.layer_norm_emb.bias', 'bert.encoder.image_embeddings.image_embeddings.weight', 'bert.encoder.image_embeddings.image_embeddings.bias', 'bert.encoder.image_embeddings.image_distbution_embeddings.weight', 'bert.encoder.image_embeddings.image_distbution_embeddings.bias', 'bert.encoder.image_embeddings.image_location_embeddings.weight', 'bert.encoder.image_embeddings.image_location_embeddings.bias', 'bert.encoder.image_embeddings.LayerNorm.weight', 'bert.encoder.image_embeddings.LayerNorm.bias', 'bert.encoder.refine_embeddings.layers.0.self_attn.linears.0.weight', 'bert.encoder.refine_embeddings.layers.0.self_attn.linears.0.bias', 'bert.encoder.refine_embeddings.layers.0.self_attn.linears.1.weight', 'bert.encoder.refine_embeddings.layers.0.self_attn.linears.1.bias', 'bert.encoder.refine_embeddings.layers.0.self_attn.linears.2.weight', 'bert.encoder.refine_embeddings.layers.0.self_attn.linears.2.bias', 'bert.encoder.refine_embeddings.layers.0.self_attn.aoa_layer.0.weight', 'bert.encoder.refine_embeddings.layers.0.self_attn.aoa_layer.0.bias', 'bert.encoder.refine_embeddings.layers.0.feed_forward.lin1.weight', 'bert.encoder.refine_embeddings.layers.0.feed_forward.lin1.bias', 'bert.encoder.refine_embeddings.layers.0.feed_forward.lin2.weight', 'bert.encoder.refine_embeddings.layers.0.feed_forward.lin2.bias', 'bert.encoder.refine_embeddings.layers.0.sublayer.0.norm.weight', 'bert.encoder.refine_embeddings.layers.0.sublayer.0.norm.bias', 'bert.encoder.refine_embeddings.layers.0.sublayer.1.norm.weight', 'bert.encoder.refine_embeddings.layers.0.sublayer.1.norm.bias', 'bert.encoder.refine_embeddings.layers.1.self_attn.linears.0.weight', 'bert.encoder.refine_embeddings.layers.1.self_attn.linears.0.bias', 'bert.encoder.refine_embeddings.layers.1.self_attn.linears.1.weight', 'bert.encoder.refine_embeddings.layers.1.self_attn.linears.1.bias', 'bert.encoder.refine_embeddings.layers.1.self_attn.linears.2.weight', 'bert.encoder.refine_embeddings.layers.1.self_attn.linears.2.bias', 'bert.encoder.refine_embeddings.layers.1.self_attn.aoa_layer.0.weight', 'bert.encoder.refine_embeddings.layers.1.self_attn.aoa_layer.0.bias', 'bert.encoder.refine_embeddings.layers.1.feed_forward.lin1.weight', 'bert.encoder.refine_embeddings.layers.1.feed_forward.lin1.bias', 'bert.encoder.refine_embeddings.layers.1.feed_forward.lin2.weight', 'bert.encoder.refine_embeddings.layers.1.feed_forward.lin2.bias', 'bert.encoder.refine_embeddings.layers.1.sublayer.0.norm.weight', 'bert.encoder.refine_embeddings.layers.1.sublayer.0.norm.bias', 'bert.encoder.refine_embeddings.layers.1.sublayer.1.norm.weight', 'bert.encoder.refine_embeddings.layers.1.sublayer.1.norm.bias', 'bert.encoder.refine_embeddings.layers.2.self_attn.linears.0.weight', 'bert.encoder.refine_embeddings.layers.2.self_attn.linears.0.bias', 'bert.encoder.refine_embeddings.layers.2.self_attn.linears.1.weight', 'bert.encoder.refine_embeddings.layers.2.self_attn.linears.1.bias', 'bert.encoder.refine_embeddings.layers.2.self_attn.linears.2.weight', 'bert.encoder.refine_embeddings.layers.2.self_attn.linears.2.bias', 'bert.encoder.refine_embeddings.layers.2.self_attn.aoa_layer.0.weight', 'bert.encoder.refine_embeddings.layers.2.self_attn.aoa_layer.0.bias', 'bert.encoder.refine_embeddings.layers.2.feed_forward.lin1.weight', 'bert.encoder.refine_embeddings.layers.2.feed_forward.lin1.bias', 'bert.encoder.refine_embeddings.layers.2.feed_forward.lin2.weight', 'bert.encoder.refine_embeddings.layers.2.feed_forward.lin2.bias', 'bert.encoder.refine_embeddings.layers.2.sublayer.0.norm.weight', 'bert.encoder.refine_embeddings.layers.2.sublayer.0.norm.bias', 'bert.encoder.refine_embeddings.layers.2.sublayer.1.norm.weight', 'bert.encoder.refine_embeddings.layers.2.sublayer.1.norm.bias', 'bert.encoder.refine_embeddings.layers.3.self_attn.linears.0.weight', 'bert.encoder.refine_embeddings.layers.3.self_attn.linears.0.bias', 'bert.encoder.refine_embeddings.layers.3.self_attn.linears.1.weight', 'bert.encoder.refine_embeddings.layers.3.self_attn.linears.1.bias', 'bert.encoder.refine_embeddings.layers.3.self_attn.linears.2.weight', 'bert.encoder.refine_embeddings.layers.3.self_attn.linears.2.bias', 'bert.encoder.refine_embeddings.layers.3.self_attn.aoa_layer.0.weight', 'bert.encoder.refine_embeddings.layers.3.self_attn.aoa_layer.0.bias', 'bert.encoder.refine_embeddings.layers.3.feed_forward.lin1.weight', 'bert.encoder.refine_embeddings.layers.3.feed_forward.lin1.bias', 'bert.encoder.refine_embeddings.layers.3.feed_forward.lin2.weight', 'bert.encoder.refine_embeddings.layers.3.feed_forward.lin2.bias', 'bert.encoder.refine_embeddings.layers.3.sublayer.0.norm.weight', 'bert.encoder.refine_embeddings.layers.3.sublayer.0.norm.bias', 'bert.encoder.refine_embeddings.layers.3.sublayer.1.norm.weight', 'bert.encoder.refine_embeddings.layers.3.sublayer.1.norm.bias', 'bert.encoder.refine_embeddings.layers.4.self_attn.linears.0.weight', 'bert.encoder.refine_embeddings.layers.4.self_attn.linears.0.bias', 'bert.encoder.refine_embeddings.layers.4.self_attn.linears.1.weight', 'bert.encoder.refine_embeddings.layers.4.self_attn.linears.1.bias', 'bert.encoder.refine_embeddings.layers.4.self_attn.linears.2.weight', 'bert.encoder.refine_embeddings.layers.4.self_attn.linears.2.bias', 'bert.encoder.refine_embeddings.layers.4.self_attn.aoa_layer.0.weight', 'bert.encoder.refine_embeddings.layers.4.self_attn.aoa_layer.0.bias', 'bert.encoder.refine_embeddings.layers.4.feed_forward.lin1.weight', 'bert.encoder.refine_embeddings.layers.4.feed_forward.lin1.bias', 'bert.encoder.refine_embeddings.layers.4.feed_forward.lin2.weight', 'bert.encoder.refine_embeddings.layers.4.feed_forward.lin2.bias', 'bert.encoder.refine_embeddings.layers.4.sublayer.0.norm.weight', 'bert.encoder.refine_embeddings.layers.4.sublayer.0.norm.bias', 'bert.encoder.refine_embeddings.layers.4.sublayer.1.norm.weight', 'bert.encoder.refine_embeddings.layers.4.sublayer.1.norm.bias', 'bert.encoder.refine_embeddings.layers.5.self_attn.linears.0.weight', 'bert.encoder.refine_embeddings.layers.5.self_attn.linears.0.bias', 'bert.encoder.refine_embeddings.layers.5.self_attn.linears.1.weight', 'bert.encoder.refine_embeddings.layers.5.self_attn.linears.1.bias', 'bert.encoder.refine_embeddings.layers.5.self_attn.linears.2.weight', 'bert.encoder.refine_embeddings.layers.5.self_attn.linears.2.bias', 'bert.encoder.refine_embeddings.layers.5.self_attn.aoa_layer.0.weight', 'bert.encoder.refine_embeddings.layers.5.self_attn.aoa_layer.0.bias', 'bert.encoder.refine_embeddings.layers.5.feed_forward.lin1.weight', 'bert.encoder.refine_embeddings.layers.5.feed_forward.lin1.bias', 'bert.encoder.refine_embeddings.layers.5.feed_forward.lin2.weight', 'bert.encoder.refine_embeddings.layers.5.feed_forward.lin2.bias', 'bert.encoder.refine_embeddings.layers.5.sublayer.0.norm.weight', 'bert.encoder.refine_embeddings.layers.5.sublayer.0.norm.bias', 'bert.encoder.refine_embeddings.layers.5.sublayer.1.norm.weight', 'bert.encoder.refine_embeddings.layers.5.sublayer.1.norm.bias', 'bert.encoder.refine_embeddings.norm.weight', 'bert.encoder.refine_embeddings.norm.bias', 'bert.encoder.cross_alignment.att_weight_c.weight', 'bert.encoder.cross_alignment.att_weight_c.bias', 'bert.encoder.cross_alignment.att_weight_q.weight', 'bert.encoder.cross_alignment.att_weight_q.bias', 'bert.encoder.cross_alignment.att_weight_cq.weight', 'bert.encoder.cross_alignment.att_weight_cq.bias', 'bert.encoder.cross_alignment.align_output.weight', 'bert.encoder.cross_alignment.align_output.bias', 'bert.encoder.cross_alignment.layer_norm.weight', 'bert.encoder.cross_alignment.layer_norm.bias', 'bert.encoder.attentions.0.q_lin.weight', 'bert.encoder.attentions.0.q_lin.bias', 'bert.encoder.attentions.0.k_lin.weight', 'bert.encoder.attentions.0.k_lin.bias', 'bert.encoder.attentions.0.v_lin.weight', 'bert.encoder.attentions.0.v_lin.bias', 'bert.encoder.attentions.0.out_lin.weight', 'bert.encoder.attentions.0.out_lin.bias', 'bert.encoder.attentions.1.q_lin.weight', 'bert.encoder.attentions.1.q_lin.bias', 'bert.encoder.attentions.1.k_lin.weight', 'bert.encoder.attentions.1.k_lin.bias', 'bert.encoder.attentions.1.v_lin.weight', 'bert.encoder.attentions.1.v_lin.bias', 'bert.encoder.attentions.1.out_lin.weight', 'bert.encoder.attentions.1.out_lin.bias', 'bert.encoder.attentions.2.q_lin.weight', 'bert.encoder.attentions.2.q_lin.bias', 'bert.encoder.attentions.2.k_lin.weight', 'bert.encoder.attentions.2.k_lin.bias', 'bert.encoder.attentions.2.v_lin.weight', 'bert.encoder.attentions.2.v_lin.bias', 'bert.encoder.attentions.2.out_lin.weight', 'bert.encoder.attentions.2.out_lin.bias', 'bert.encoder.attentions.3.q_lin.weight', 'bert.encoder.attentions.3.q_lin.bias', 'bert.encoder.attentions.3.k_lin.weight', 'bert.encoder.attentions.3.k_lin.bias', 'bert.encoder.attentions.3.v_lin.weight', 'bert.encoder.attentions.3.v_lin.bias', 'bert.encoder.attentions.3.out_lin.weight', 'bert.encoder.attentions.3.out_lin.bias', 'bert.encoder.attentions.4.q_lin.weight', 'bert.encoder.attentions.4.q_lin.bias', 'bert.encoder.attentions.4.k_lin.weight', 'bert.encoder.attentions.4.k_lin.bias', 'bert.encoder.attentions.4.v_lin.weight', 'bert.encoder.attentions.4.v_lin.bias', 'bert.encoder.attentions.4.out_lin.weight', 'bert.encoder.attentions.4.out_lin.bias', 'bert.encoder.attentions.5.q_lin.weight', 'bert.encoder.attentions.5.q_lin.bias', 'bert.encoder.attentions.5.k_lin.weight', 'bert.encoder.attentions.5.k_lin.bias', 'bert.encoder.attentions.5.v_lin.weight', 'bert.encoder.attentions.5.v_lin.bias', 'bert.encoder.attentions.5.out_lin.weight', 'bert.encoder.attentions.5.out_lin.bias', 'bert.encoder.attentions.6.q_lin.weight', 'bert.encoder.attentions.6.q_lin.bias', 'bert.encoder.attentions.6.k_lin.weight', 'bert.encoder.attentions.6.k_lin.bias', 'bert.encoder.attentions.6.v_lin.weight', 'bert.encoder.attentions.6.v_lin.bias', 'bert.encoder.attentions.6.out_lin.weight', 'bert.encoder.attentions.6.out_lin.bias', 'bert.encoder.attentions.7.q_lin.weight', 'bert.encoder.attentions.7.q_lin.bias', 'bert.encoder.attentions.7.k_lin.weight', 'bert.encoder.attentions.7.k_lin.bias', 'bert.encoder.attentions.7.v_lin.weight', 'bert.encoder.attentions.7.v_lin.bias', 'bert.encoder.attentions.7.out_lin.weight', 'bert.encoder.attentions.7.out_lin.bias', 'bert.encoder.attentions.8.q_lin.weight', 'bert.encoder.attentions.8.q_lin.bias', 'bert.encoder.attentions.8.k_lin.weight', 'bert.encoder.attentions.8.k_lin.bias', 'bert.encoder.attentions.8.v_lin.weight', 'bert.encoder.attentions.8.v_lin.bias', 'bert.encoder.attentions.8.out_lin.weight', 'bert.encoder.attentions.8.out_lin.bias', 'bert.encoder.attentions.9.q_lin.weight', 'bert.encoder.attentions.9.q_lin.bias', 'bert.encoder.attentions.9.k_lin.weight', 'bert.encoder.attentions.9.k_lin.bias', 'bert.encoder.attentions.9.v_lin.weight', 'bert.encoder.attentions.9.v_lin.bias', 'bert.encoder.attentions.9.out_lin.weight', 'bert.encoder.attentions.9.out_lin.bias', 'bert.encoder.attentions.10.q_lin.weight', 'bert.encoder.attentions.10.q_lin.bias', 'bert.encoder.attentions.10.k_lin.weight', 'bert.encoder.attentions.10.k_lin.bias', 'bert.encoder.attentions.10.v_lin.weight', 'bert.encoder.attentions.10.v_lin.bias', 'bert.encoder.attentions.10.out_lin.weight', 'bert.encoder.attentions.10.out_lin.bias', 'bert.encoder.attentions.11.q_lin.weight', 'bert.encoder.attentions.11.q_lin.bias', 'bert.encoder.attentions.11.k_lin.weight', 'bert.encoder.attentions.11.k_lin.bias', 'bert.encoder.attentions.11.v_lin.weight', 'bert.encoder.attentions.11.v_lin.bias', 'bert.encoder.attentions.11.out_lin.weight', 'bert.encoder.attentions.11.out_lin.bias', 'bert.encoder.layer_norm1.0.weight', 'bert.encoder.layer_norm1.0.bias', 'bert.encoder.layer_norm1.1.weight', 'bert.encoder.layer_norm1.1.bias', 'bert.encoder.layer_norm1.2.weight', 'bert.encoder.layer_norm1.2.bias', 'bert.encoder.layer_norm1.3.weight', 'bert.encoder.layer_norm1.3.bias', 'bert.encoder.layer_norm1.4.weight', 'bert.encoder.layer_norm1.4.bias', 'bert.encoder.layer_norm1.5.weight', 'bert.encoder.layer_norm1.5.bias', 'bert.encoder.layer_norm1.6.weight', 'bert.encoder.layer_norm1.6.bias', 'bert.encoder.layer_norm1.7.weight', 'bert.encoder.layer_norm1.7.bias', 'bert.encoder.layer_norm1.8.weight', 'bert.encoder.layer_norm1.8.bias', 'bert.encoder.layer_norm1.9.weight', 'bert.encoder.layer_norm1.9.bias', 'bert.encoder.layer_norm1.10.weight', 'bert.encoder.layer_norm1.10.bias', 'bert.encoder.layer_norm1.11.weight', 'bert.encoder.layer_norm1.11.bias', 'bert.encoder.ffns.0.lin1.weight', 'bert.encoder.ffns.0.lin1.bias', 'bert.encoder.ffns.0.lin2.weight', 'bert.encoder.ffns.0.lin2.bias', 'bert.encoder.ffns.1.lin1.weight', 'bert.encoder.ffns.1.lin1.bias', 'bert.encoder.ffns.1.lin2.weight', 'bert.encoder.ffns.1.lin2.bias', 'bert.encoder.ffns.2.lin1.weight', 'bert.encoder.ffns.2.lin1.bias', 'bert.encoder.ffns.2.lin2.weight', 'bert.encoder.ffns.2.lin2.bias', 'bert.encoder.ffns.3.lin1.weight', 'bert.encoder.ffns.3.lin1.bias', 'bert.encoder.ffns.3.lin2.weight', 'bert.encoder.ffns.3.lin2.bias', 'bert.encoder.ffns.4.lin1.weight', 'bert.encoder.ffns.4.lin1.bias', 'bert.encoder.ffns.4.lin2.weight', 'bert.encoder.ffns.4.lin2.bias', 'bert.encoder.ffns.5.lin1.weight', 'bert.encoder.ffns.5.lin1.bias', 'bert.encoder.ffns.5.lin2.weight', 'bert.encoder.ffns.5.lin2.bias', 'bert.encoder.ffns.6.lin1.weight', 'bert.encoder.ffns.6.lin1.bias', 'bert.encoder.ffns.6.lin2.weight', 'bert.encoder.ffns.6.lin2.bias', 'bert.encoder.ffns.7.lin1.weight', 'bert.encoder.ffns.7.lin1.bias', 'bert.encoder.ffns.7.lin2.weight', 'bert.encoder.ffns.7.lin2.bias', 'bert.encoder.ffns.8.lin1.weight', 'bert.encoder.ffns.8.lin1.bias', 'bert.encoder.ffns.8.lin2.weight', 'bert.encoder.ffns.8.lin2.bias', 'bert.encoder.ffns.9.lin1.weight', 'bert.encoder.ffns.9.lin1.bias', 'bert.encoder.ffns.9.lin2.weight', 'bert.encoder.ffns.9.lin2.bias', 'bert.encoder.ffns.10.lin1.weight', 'bert.encoder.ffns.10.lin1.bias', 'bert.encoder.ffns.10.lin2.weight', 'bert.encoder.ffns.10.lin2.bias', 'bert.encoder.ffns.11.lin1.weight', 'bert.encoder.ffns.11.lin1.bias', 'bert.encoder.ffns.11.lin2.weight', 'bert.encoder.ffns.11.lin2.bias', 'bert.encoder.layer_norm2.0.weight', 'bert.encoder.layer_norm2.0.bias', 'bert.encoder.layer_norm2.1.weight', 'bert.encoder.layer_norm2.1.bias', 'bert.encoder.layer_norm2.2.weight', 'bert.encoder.layer_norm2.2.bias', 'bert.encoder.layer_norm2.3.weight', 'bert.encoder.layer_norm2.3.bias', 'bert.encoder.layer_norm2.4.weight', 'bert.encoder.layer_norm2.4.bias', 'bert.encoder.layer_norm2.5.weight', 'bert.encoder.layer_norm2.5.bias', 'bert.encoder.layer_norm2.6.weight', 'bert.encoder.layer_norm2.6.bias', 'bert.encoder.layer_norm2.7.weight', 'bert.encoder.layer_norm2.7.bias', 'bert.encoder.layer_norm2.8.weight', 'bert.encoder.layer_norm2.8.bias', 'bert.encoder.layer_norm2.9.weight', 'bert.encoder.layer_norm2.9.bias', 'bert.encoder.layer_norm2.10.weight', 'bert.encoder.layer_norm2.10.bias', 'bert.encoder.layer_norm2.11.weight', 'bert.encoder.layer_norm2.11.bias', 'bert.encoder.layer_norm15.0.weight', 'bert.encoder.layer_norm15.0.bias', 'bert.encoder.layer_norm15.1.weight', 'bert.encoder.layer_norm15.1.bias', 'bert.encoder.layer_norm15.2.weight', 'bert.encoder.layer_norm15.2.bias', 'bert.encoder.layer_norm15.3.weight', 'bert.encoder.layer_norm15.3.bias', 'bert.encoder.layer_norm15.4.weight', 'bert.encoder.layer_norm15.4.bias', 'bert.encoder.layer_norm15.5.weight', 'bert.encoder.layer_norm15.5.bias', 'bert.encoder.layer_norm15.6.weight', 'bert.encoder.layer_norm15.6.bias', 'bert.encoder.layer_norm15.7.weight', 'bert.encoder.layer_norm15.7.bias', 'bert.encoder.layer_norm15.8.weight', 'bert.encoder.layer_norm15.8.bias', 'bert.encoder.layer_norm15.9.weight', 'bert.encoder.layer_norm15.9.bias', 'bert.encoder.layer_norm15.10.weight', 'bert.encoder.layer_norm15.10.bias', 'bert.encoder.layer_norm15.11.weight', 'bert.encoder.layer_norm15.11.bias', 'bert.encoder.encoder_attn.0.q_lin.weight', 'bert.encoder.encoder_attn.0.q_lin.bias', 'bert.encoder.encoder_attn.0.k_lin.weight', 'bert.encoder.encoder_attn.0.k_lin.bias', 'bert.encoder.encoder_attn.0.v_lin.weight', 'bert.encoder.encoder_attn.0.v_lin.bias', 'bert.encoder.encoder_attn.0.out_lin.weight', 'bert.encoder.encoder_attn.0.out_lin.bias', 'bert.encoder.encoder_attn.1.q_lin.weight', 'bert.encoder.encoder_attn.1.q_lin.bias', 'bert.encoder.encoder_attn.1.k_lin.weight', 'bert.encoder.encoder_attn.1.k_lin.bias', 'bert.encoder.encoder_attn.1.v_lin.weight', 'bert.encoder.encoder_attn.1.v_lin.bias', 'bert.encoder.encoder_attn.1.out_lin.weight', 'bert.encoder.encoder_attn.1.out_lin.bias', 'bert.encoder.encoder_attn.2.q_lin.weight', 'bert.encoder.encoder_attn.2.q_lin.bias', 'bert.encoder.encoder_attn.2.k_lin.weight', 'bert.encoder.encoder_attn.2.k_lin.bias', 'bert.encoder.encoder_attn.2.v_lin.weight', 'bert.encoder.encoder_attn.2.v_lin.bias', 'bert.encoder.encoder_attn.2.out_lin.weight', 'bert.encoder.encoder_attn.2.out_lin.bias', 'bert.encoder.encoder_attn.3.q_lin.weight', 'bert.encoder.encoder_attn.3.q_lin.bias', 'bert.encoder.encoder_attn.3.k_lin.weight', 'bert.encoder.encoder_attn.3.k_lin.bias', 'bert.encoder.encoder_attn.3.v_lin.weight', 'bert.encoder.encoder_attn.3.v_lin.bias', 'bert.encoder.encoder_attn.3.out_lin.weight', 'bert.encoder.encoder_attn.3.out_lin.bias', 'bert.encoder.encoder_attn.4.q_lin.weight', 'bert.encoder.encoder_attn.4.q_lin.bias', 'bert.encoder.encoder_attn.4.k_lin.weight', 'bert.encoder.encoder_attn.4.k_lin.bias', 'bert.encoder.encoder_attn.4.v_lin.weight', 'bert.encoder.encoder_attn.4.v_lin.bias', 'bert.encoder.encoder_attn.4.out_lin.weight', 'bert.encoder.encoder_attn.4.out_lin.bias', 'bert.encoder.encoder_attn.5.q_lin.weight', 'bert.encoder.encoder_attn.5.q_lin.bias', 'bert.encoder.encoder_attn.5.k_lin.weight', 'bert.encoder.encoder_attn.5.k_lin.bias', 'bert.encoder.encoder_attn.5.v_lin.weight', 'bert.encoder.encoder_attn.5.v_lin.bias', 'bert.encoder.encoder_attn.5.out_lin.weight', 'bert.encoder.encoder_attn.5.out_lin.bias', 'bert.encoder.encoder_attn.6.q_lin.weight', 'bert.encoder.encoder_attn.6.q_lin.bias', 'bert.encoder.encoder_attn.6.k_lin.weight', 'bert.encoder.encoder_attn.6.k_lin.bias', 'bert.encoder.encoder_attn.6.v_lin.weight', 'bert.encoder.encoder_attn.6.v_lin.bias', 'bert.encoder.encoder_attn.6.out_lin.weight', 'bert.encoder.encoder_attn.6.out_lin.bias', 'bert.encoder.encoder_attn.7.q_lin.weight', 'bert.encoder.encoder_attn.7.q_lin.bias', 'bert.encoder.encoder_attn.7.k_lin.weight', 'bert.encoder.encoder_attn.7.k_lin.bias', 'bert.encoder.encoder_attn.7.v_lin.weight', 'bert.encoder.encoder_attn.7.v_lin.bias', 'bert.encoder.encoder_attn.7.out_lin.weight', 'bert.encoder.encoder_attn.7.out_lin.bias', 'bert.encoder.encoder_attn.8.q_lin.weight', 'bert.encoder.encoder_attn.8.q_lin.bias', 'bert.encoder.encoder_attn.8.k_lin.weight', 'bert.encoder.encoder_attn.8.k_lin.bias', 'bert.encoder.encoder_attn.8.v_lin.weight', 'bert.encoder.encoder_attn.8.v_lin.bias', 'bert.encoder.encoder_attn.8.out_lin.weight', 'bert.encoder.encoder_attn.8.out_lin.bias', 'bert.encoder.encoder_attn.9.q_lin.weight', 'bert.encoder.encoder_attn.9.q_lin.bias', 'bert.encoder.encoder_attn.9.k_lin.weight', 'bert.encoder.encoder_attn.9.k_lin.bias', 'bert.encoder.encoder_attn.9.v_lin.weight', 'bert.encoder.encoder_attn.9.v_lin.bias', 'bert.encoder.encoder_attn.9.out_lin.weight', 'bert.encoder.encoder_attn.9.out_lin.bias', 'bert.encoder.encoder_attn.10.q_lin.weight', 'bert.encoder.encoder_attn.10.q_lin.bias', 'bert.encoder.encoder_attn.10.k_lin.weight', 'bert.encoder.encoder_attn.10.k_lin.bias', 'bert.encoder.encoder_attn.10.v_lin.weight', 'bert.encoder.encoder_attn.10.v_lin.bias', 'bert.encoder.encoder_attn.10.out_lin.weight', 'bert.encoder.encoder_attn.10.out_lin.bias', 'bert.encoder.encoder_attn.11.q_lin.weight', 'bert.encoder.encoder_attn.11.q_lin.bias', 'bert.encoder.encoder_attn.11.k_lin.weight', 'bert.encoder.encoder_attn.11.k_lin.bias', 'bert.encoder.encoder_attn.11.v_lin.weight', 'bert.encoder.encoder_attn.11.v_lin.bias', 'bert.encoder.encoder_attn.11.out_lin.weight', 'bert.encoder.encoder_attn.11.out_lin.bias', 'bert.encoder.latent_transforms.0.x_to_mu.weight', 'bert.encoder.latent_transforms.0.x_to_mu.bias', 'bert.encoder.latent_transforms.0.x_to_logvar.weight', 'bert.encoder.latent_transforms.0.x_to_logvar.bias', 'bert.encoder.latent_transforms.0.out_dense.weight', 'bert.encoder.latent_transforms.0.out_dense.bias', 'bert.encoder.latent_transforms.1.x_to_mu.weight', 'bert.encoder.latent_transforms.1.x_to_mu.bias', 'bert.encoder.latent_transforms.1.x_to_logvar.weight', 'bert.encoder.latent_transforms.1.x_to_logvar.bias', 'bert.encoder.latent_transforms.1.out_dense.weight', 'bert.encoder.latent_transforms.1.out_dense.bias', 'bert.encoder.original_transforms.0.dense.weight', 'bert.encoder.original_transforms.0.dense.bias', 'bert.encoder.original_transforms.0.dense_mu.weight', 'bert.encoder.original_transforms.0.dense_mu.bias', 'bert.encoder.original_transforms.0.LayerNorm.weight', 'bert.encoder.original_transforms.0.LayerNorm.bias', 'bert.encoder.original_transforms.1.dense.weight', 'bert.encoder.original_transforms.1.dense.bias', 'bert.encoder.original_transforms.1.dense_mu.weight', 'bert.encoder.original_transforms.1.dense_mu.bias', 'bert.encoder.original_transforms.1.LayerNorm.weight', 'bert.encoder.original_transforms.1.LayerNorm.bias', 'bert.encoder.pooled_layer.dense.weight', 'bert.encoder.pooled_layer.dense.bias', 'bert.encoder.seq_relationship.weight', 'bert.encoder.seq_relationship.bias', 'bert.encoder.pooled_layer2.dense.weight', 'bert.encoder.pooled_layer2.dense.bias', 'bert.encoder.seq_relationship2.weight', 'bert.encoder.seq_relationship2.bias', 'bert.encoder.mrfr_dense.weight', 'bert.encoder.mrfr_dense.bias', 'bert.encoder.transformer_obj.dense.weight', 'bert.encoder.transformer_obj.dense.bias', 'bert.encoder.transformer_obj.LayerNorm.weight', 'bert.encoder.transformer_obj.LayerNorm.bias', 'bert.encoder.pred_layer.proj.weight', 'bert.encoder.pred_layer.proj.bias', 'bert.encoder.pred_obj_layer.proj.weight', 'bert.encoder.pred_obj_layer.proj.bias'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"/science/image/nlp-datasets/emanuele/checkpoints/iglue/conversions/pretrain/m3p_checkpoint_22.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'M3PConfig' object has no attribute 'n_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-203bc50516bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/science/image/nlp-datasets/emanuele/checkpoints/iglue/conversions/pretrain/m3p_checkpoint_22.bin\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM3PForVLTasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/iglue/volta/volta/utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;31m# Instantiate model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/iglue/volta/volta/encoders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, task_cfg, task_ids, dropout_prob)\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM3PForVLTasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM3PModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0;31m# FIXME ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/iglue/volta/volta/encoders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM3PModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM3PTransformerModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_encoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_crossModal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# params, is_encoder, with_output, is_crossModal=False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooled_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/iglue/volta/volta/m3p_transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, is_encoder, with_output, is_crossModal)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m  \u001b[0;31m# 2048 by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m  \u001b[0;31m# 8 by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_encoder\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dec_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'M3PConfig' object has no attribute 'n_layers'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import argparse\n",
    "sys.path.append(\"../\")\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import torch\n",
    "from volta.config import M3PConfig\n",
    "from volta.encoders import M3PForVLTasks\n",
    "\n",
    "\n",
    "# # Inputs\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--input_fn\", type=str, default=\"Epoch20_LXRT.pth\")\n",
    "# parser.add_argument(\"--output_fn\", type=str, default=\"lxmert_checkpoint_19.bin\")\n",
    "# parser.add_argument(\"--verbose\", action=\"store_true\", default=False)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# Load original checkpoint\n",
    "# original_ckpt = torch.load(args.input_fn, map_location=\"cpu\")\n",
    "\n",
    "# Create corresponding VOLTA model\n",
    "config_file = \"../config/m3p_base.json\"\n",
    "config = M3PConfig.from_json_file(config_file)\n",
    "\n",
    "tasks_config_file = \"../config_tasks/iglue_ku_trainval_tasks.yml\"\n",
    "with open(tasks_config_file, \"r\") as f:\n",
    "    task_cfg = edict(yaml.safe_load(f))\n",
    "task_id = '21'\n",
    "task = \"TASK\" + task_id\n",
    "\n",
    "ckpt_path = \"/science/image/nlp-datasets/emanuele/checkpoints/iglue/conversions/pretrain/m3p_checkpoint_22.bin\"\n",
    "model = M3PForVLTasks.from_pretrained(ckpt_path, config=config, task_cfg=task_cfg, task_ids=[task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ckpt['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['n_layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dump_path', 'exp_name', 'save_periodic', 'exp_id', 'fp16', 'encoder_only', 'english_only', 'emb_dim', 'n_layers', 'n_dec_layers', 'n_heads', 'dropout', 'attention_dropout', 'gelu_activation', 'share_inout_emb', 'sinusoidal_embeddings', 'attention_setting', 'asm', 'context_size', 'word_pred', 'sample_alpha', 'word_mask_keep_rand', 'word_shuffle', 'word_dropout', 'word_blank', 'word_mass', 'data_path', 'lgs', 'src_lgs', 'ag_lgs', 'lg_sampling_factor', 'vocab_path', 'input_fea_dir', 'google_path', 'sbu_path', 'coco_path', 'flicker_path', 'mild_path', 'slide_path', 'max_vocab', 'min_count', 'batch_size', 'seq_per_img', 'max_region_num', 'bptt', 'min_len', 'max_len', 'group_by_size', 'max_batch_size', 'tokens_per_batch', 'split_data', 'optimizer', 'clip_grad_norm', 'epoch_size', 'max_epoch', 'stopping_criterion', 'validation_metrics', 'lambda_mlm', 'lambda_clm', 'lambda_pc', 'lambda_mass', 'lambda_ic', 'lambda_imlm', 'lambda_ida', 'lambda_tifg', 'lambda_rel', 'lambda_mrm', 'lambda_mrfr', 'lambda_t2i', 'lambda_i2t', 'clm_steps', 'mlm_steps', 'mass_steps', 'mt_steps', 'ae_steps', 'bt_steps', 'pc_steps', 'cross_modal_steps', 'cross_mass_steps', 'cross_ae_steps', 'cross_gan_steps', 'cross_rel_steps', 'cross_mlm_steps', 'cross_mrm_steps', 'cross_mrfr_steps', 'text_steps', 'reload_model', 'reload_checkpoint', 'beam_size', 'length_penalty', 'early_stopping', 'eval_bleu', 'eval_only', 'debug_train', 'debug_pretrain', 'debug_slurm', 'local_rank', 'master_port', 'refine_image', 'refine_layers', 'refine_encoder', 'use_noise', 'accumulate_gradients', 'amp', 'use_memory', 'is_cross_modal', 'is_understanding', 'is_generation', 'is_pretrain', 'use_externel_att', 'use_enc_att', 'save_every_epoch', 'multi_reload_model', 'bin_cls_loss_weight', 'multi_cls_loss_weight', 'sent_ratio', 'word_ratio', 'sample_n', 't2i_flag', 'i2t_flag', 'coco_method', 'eval_n', 'eval_images', 'retrieval_batch', 'retrieval_workers', 'test_splits', 'use_new_fea', 'eval_path', 'google_valid_path', 'train_order_path', 'cross_lingual_path', 'num_workers', 'ft_lgs', 'is_latent', 'kld_alpha', 'rec_alpha', 'is_mild', 'qp_type', 'ft_all', 'is_mt', 'mt_only_text', 'is_ntg', 'is_slide', 'is_freelb', 'free_text', 'free_img', 'langs', 'id2lang', 'lang2id', 'n_langs', 'mono_dataset', 'para_dataset', 'eos_index', 'pad_index', 'mask_index', 'n_words', 'word_mask', 'word_keep', 'word_rand', 'is_slurm_job', 'global_rank', 'world_size', 'n_gpu_per_node', 'n_nodes', 'node_id', 'is_master', 'multi_node', 'multi_gpu', 'command', 'pred_probs', 'lambda_mlm_config', 'lambda_mass_config', 'lambda_ic_config', 'lambda_imlm_config', 'lambda_ida_config', 'lambda_tifg_config', 'lambda_rel_config', 'lambda_mrm_config', 'lambda_mrfr_config', 'lambda_t2i_config', 'lambda_i2t_config'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForVLPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): UC2Embeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768)\n",
       "      (new_token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (image_embeddings): Linear(in_features=2048, out_features=768, bias=True)\n",
       "      (image_location_embeddings): Linear(in_features=7, out_features=768, bias=True)\n",
       "      (image_token_type_embeddings): Embedding(2, 768)\n",
       "      (image_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (image_location_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (4): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (5): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (6): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (7): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (8): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (9): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (10): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (11): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (12): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (13): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (14): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (15): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (16): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (17): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (18): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (19): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (20): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (21): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (22): BertGatedAttention(\n",
       "          (attention_self): BertGatedSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attention_output): BertGatedSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (23): BertGatedFeedForward(\n",
       "          (intermediate): BertGatedIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (v_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertGatedOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (v_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (v_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (v_LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (t_pooler): BertTextPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=250002, bias=False)\n",
       "    )\n",
       "    (bi_seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "    (imagePredictions): BertImagePredictionHead(\n",
       "      (transform): BertImgPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder_dict): ModuleDict(\n",
       "        (0): Linear(in_features=768, out_features=1601, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (loss_fct): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250002, 768] \t bert.embeddings.word_embeddings.weight\n",
      "[514, 768] \t bert.embeddings.position_embeddings.weight\n",
      "[2, 768] \t bert.embeddings.new_token_type_embeddings.weight\n",
      "[768] \t bert.embeddings.LayerNorm.weight\n",
      "[768] \t bert.embeddings.LayerNorm.bias\n",
      "[768, 2048] \t bert.embeddings.image_embeddings.weight\n",
      "[768] \t bert.embeddings.image_embeddings.bias\n",
      "[768, 7] \t bert.embeddings.image_location_embeddings.weight\n",
      "[768] \t bert.embeddings.image_location_embeddings.bias\n",
      "[2, 768] \t bert.embeddings.image_token_type_embeddings.weight\n",
      "[768] \t bert.embeddings.image_layer_norm.weight\n",
      "[768] \t bert.embeddings.image_layer_norm.bias\n",
      "[768] \t bert.embeddings.image_location_layer_norm.weight\n",
      "[768] \t bert.embeddings.image_location_layer_norm.bias\n",
      "[768] \t bert.embeddings.v_LayerNorm.weight\n",
      "[768] \t bert.embeddings.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.0.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.0.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.0.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.0.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.0.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.0.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.0.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.0.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.0.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.0.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.0.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.0.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.0.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.1.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.1.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.1.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.1.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.1.output.dense.weight\n",
      "[768] \t bert.encoder.layer.1.output.dense.bias\n",
      "[768] \t bert.encoder.layer.1.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.1.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.1.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.1.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.1.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.1.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.2.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.2.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.2.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.2.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.2.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.2.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.2.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.2.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.2.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.2.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.2.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.2.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.2.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.3.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.3.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.3.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.3.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.3.output.dense.weight\n",
      "[768] \t bert.encoder.layer.3.output.dense.bias\n",
      "[768] \t bert.encoder.layer.3.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.3.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.3.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.3.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.3.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.3.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.4.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.4.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.4.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.4.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.4.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.4.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.4.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.4.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.4.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.4.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.4.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.4.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.4.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.5.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.5.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.5.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.5.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.5.output.dense.weight\n",
      "[768] \t bert.encoder.layer.5.output.dense.bias\n",
      "[768] \t bert.encoder.layer.5.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.5.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.5.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.5.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.5.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.5.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.6.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.6.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.6.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.6.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.6.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.6.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.6.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.6.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.6.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.6.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.6.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.6.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.6.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.7.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.7.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.7.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.7.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.7.output.dense.weight\n",
      "[768] \t bert.encoder.layer.7.output.dense.bias\n",
      "[768] \t bert.encoder.layer.7.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.7.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.7.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.7.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.7.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.7.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.8.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.8.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.8.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.8.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.8.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.8.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.8.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.8.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.8.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.8.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.8.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.8.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.8.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.9.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.9.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.9.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.9.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.9.output.dense.weight\n",
      "[768] \t bert.encoder.layer.9.output.dense.bias\n",
      "[768] \t bert.encoder.layer.9.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.9.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.9.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.9.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.9.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.9.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.10.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.10.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.10.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.10.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.10.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.10.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.10.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.10.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.10.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.10.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.10.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.10.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.10.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.11.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.11.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.11.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.11.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.11.output.dense.weight\n",
      "[768] \t bert.encoder.layer.11.output.dense.bias\n",
      "[768] \t bert.encoder.layer.11.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.11.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.11.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.11.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.11.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.11.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.12.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.12.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.12.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.12.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.12.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.12.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.12.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.12.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.12.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.12.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.12.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.12.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.12.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.13.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.13.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.13.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.13.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.13.output.dense.weight\n",
      "[768] \t bert.encoder.layer.13.output.dense.bias\n",
      "[768] \t bert.encoder.layer.13.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.13.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.13.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.13.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.13.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.13.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.14.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.14.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.14.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.14.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.14.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.14.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.14.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.14.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.14.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.14.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.14.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.14.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.14.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.15.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.15.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.15.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.15.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.15.output.dense.weight\n",
      "[768] \t bert.encoder.layer.15.output.dense.bias\n",
      "[768] \t bert.encoder.layer.15.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.15.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.15.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.15.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.15.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.15.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.16.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.16.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.16.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.16.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.16.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.16.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.16.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.16.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.16.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.16.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.16.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.16.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.16.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.17.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.17.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.17.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.17.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.17.output.dense.weight\n",
      "[768] \t bert.encoder.layer.17.output.dense.bias\n",
      "[768] \t bert.encoder.layer.17.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.17.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.17.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.17.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.17.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.17.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.18.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.18.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.18.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.18.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.18.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.18.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.18.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.18.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.18.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.18.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.18.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.18.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.18.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.19.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.19.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.19.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.19.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.19.output.dense.weight\n",
      "[768] \t bert.encoder.layer.19.output.dense.bias\n",
      "[768] \t bert.encoder.layer.19.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.19.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.19.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.19.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.19.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.19.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.20.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.20.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.20.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.20.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.20.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.20.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.20.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.20.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.20.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.20.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.20.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.20.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.20.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.21.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.21.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.21.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.21.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.21.output.dense.weight\n",
      "[768] \t bert.encoder.layer.21.output.dense.bias\n",
      "[768] \t bert.encoder.layer.21.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.21.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.21.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.21.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.21.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.21.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_self.query.weight\n",
      "[768] \t bert.encoder.layer.22.attention_self.query.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_self.key.weight\n",
      "[768] \t bert.encoder.layer.22.attention_self.key.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_self.value.weight\n",
      "[768] \t bert.encoder.layer.22.attention_self.value.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_self.v_query.weight\n",
      "[768] \t bert.encoder.layer.22.attention_self.v_query.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_self.v_key.weight\n",
      "[768] \t bert.encoder.layer.22.attention_self.v_key.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_self.v_value.weight\n",
      "[768] \t bert.encoder.layer.22.attention_self.v_value.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_output.dense.weight\n",
      "[768] \t bert.encoder.layer.22.attention_output.dense.bias\n",
      "[768] \t bert.encoder.layer.22.attention_output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.22.attention_output.LayerNorm.bias\n",
      "[768, 768] \t bert.encoder.layer.22.attention_output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.22.attention_output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.22.attention_output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.22.attention_output.v_LayerNorm.bias\n",
      "[3072, 768] \t bert.encoder.layer.23.intermediate.dense.weight\n",
      "[3072] \t bert.encoder.layer.23.intermediate.dense.bias\n",
      "[3072, 768] \t bert.encoder.layer.23.intermediate.v_dense.weight\n",
      "[3072] \t bert.encoder.layer.23.intermediate.v_dense.bias\n",
      "[768, 3072] \t bert.encoder.layer.23.output.dense.weight\n",
      "[768] \t bert.encoder.layer.23.output.dense.bias\n",
      "[768] \t bert.encoder.layer.23.output.LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.23.output.LayerNorm.bias\n",
      "[768, 3072] \t bert.encoder.layer.23.output.v_dense.weight\n",
      "[768] \t bert.encoder.layer.23.output.v_dense.bias\n",
      "[768] \t bert.encoder.layer.23.output.v_LayerNorm.weight\n",
      "[768] \t bert.encoder.layer.23.output.v_LayerNorm.bias\n",
      "[768, 768] \t bert.t_pooler.dense.weight\n",
      "[768] \t bert.t_pooler.dense.bias\n",
      "[250002] \t cls.predictions.bias\n",
      "[768, 768] \t cls.predictions.transform.dense.weight\n",
      "[768] \t cls.predictions.transform.dense.bias\n",
      "[768] \t cls.predictions.transform.LayerNorm.weight\n",
      "[768] \t cls.predictions.transform.LayerNorm.bias\n",
      "[250002, 768] \t cls.predictions.decoder.weight\n",
      "[2, 768] \t cls.bi_seq_relationship.weight\n",
      "[2] \t cls.bi_seq_relationship.bias\n",
      "[768, 768] \t cls.imagePredictions.transform.dense.weight\n",
      "[768] \t cls.imagePredictions.transform.dense.bias\n",
      "[768] \t cls.imagePredictions.transform.LayerNorm.weight\n",
      "[768] \t cls.imagePredictions.transform.LayerNorm.bias\n",
      "[1601, 768] \t cls.imagePredictions.decoder_dict.0.weight\n",
      "[1601] \t cls.imagePredictions.decoder_dict.0.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in trg_dict.items():\n",
    "    print(list(v.size()), '\\t', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "volta2original = dict()\n",
    "volta_keys = set(trg_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta.img_embeddings.mask_embedding.weight \t bert.embeddings.mask_embedding.weight\n",
      "cls.decoder.bias \t cls.predictions.decoder.bias\n",
      "vis_cls.bias \t vis_cls.predictions.bias\n",
      "vis_cls.dense.weight \t vis_cls.predictions.transform.dense.weight\n",
      "vis_cls.dense.bias \t vis_cls.predictions.transform.dense.bias\n",
      "vis_cls.layer_norm.weight \t vis_cls.predictions.transform.LayerNorm.weight\n",
      "vis_cls.layer_norm.bias \t vis_cls.predictions.transform.LayerNorm.bias\n",
      "vis_cls.decoder.weight \t vis_cls.predictions.decoder.weight\n",
      "vis_cls.decoder.bias \t vis_cls.predictions.decoder.bias\n",
      "feat_regress.weight \t feat_regress.weight\n",
      "feat_regress.bias \t feat_regress.bias\n",
      "feat_regress.net.0.weight \t feat_regress.net.0.weight\n",
      "feat_regress.net.0.bias \t feat_regress.net.0.bias\n",
      "feat_regress.net.2.weight \t feat_regress.net.2.weight\n",
      "feat_regress.net.2.bias \t feat_regress.net.2.bias\n",
      "region_classifier.net.0.weight \t region_classifier.net.0.weight\n",
      "region_classifier.net.0.bias \t region_classifier.net.0.bias\n",
      "region_classifier.net.2.weight \t region_classifier.net.2.weight\n",
      "region_classifier.net.2.bias \t region_classifier.net.2.bias\n",
      "region_classifier.net.3.weight \t region_classifier.net.3.weight\n",
      "region_classifier.net.3.bias \t region_classifier.net.3.bias\n"
     ]
    }
   ],
   "source": [
    "for k in uc2.keys():\n",
    "    ln = str(k)\n",
    "    ln = ln.replace(\"roberta\", \"bert\")\n",
    "    \n",
    "    ln = ln.replace(\"img_embeddings\", \"embeddings\")\n",
    "    ln = ln.replace(\"img_linear\", \"image_embeddings\")\n",
    "    ln = ln.replace(\"pos_linear\", \"image_location_embeddings\")\n",
    "    ln = ln.replace(\"img_layer_norm\", \"image_layer_norm\")\n",
    "    ln = ln.replace(\"pos_layer_norm\", \"image_location_layer_norm\")\n",
    "    \n",
    "    ln = ln.replace('attention.self', 'attention_self')\n",
    "    ln = ln.replace('attention.output', 'attention_output')\n",
    "    if '.layer.' in ln:\n",
    "        num = int(ln.split(\".\")[3])\n",
    "        new = 2*num + ('.intermediate.' in ln or '.output.' in ln)\n",
    "        ln = ln.replace(f\".{num}.\", f\".{new}.\")\n",
    "        \n",
    "    ln = ln.replace(\"pooler\", \"t_pooler\")\n",
    "    ln = ln.replace(\"cls.dense\", \"cls.predictions.transform.dense\")\n",
    "    ln = ln.replace(\"cls.layer_norm\", \"cls.predictions.transform.LayerNorm\")\n",
    "    ln = ln.replace(\"cls.bias\", \"cls.predictions.bias\")\n",
    "    ln = ln.replace(\"cls.decoder\", \"cls.predictions.decoder\")\n",
    "    ln = ln.replace(\"itm_output\", \"cls.bi_seq_relationship\")\n",
    "    \n",
    "    if ln not in volta_keys:\n",
    "        print(k, \"\\t\", ln)\n",
    "    else:\n",
    "        volta2original[ln] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_ckpt = uc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight <- roberta.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight <- roberta.embeddings.position_embeddings.weight\n",
      "bert.embeddings.new_token_type_embeddings.weight <- roberta.embeddings.new_token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight <- roberta.img_embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias <- roberta.img_embeddings.LayerNorm.bias\n",
      "bert.embeddings.image_embeddings.weight <- roberta.img_embeddings.img_linear.weight\n",
      "bert.embeddings.image_embeddings.bias <- roberta.img_embeddings.img_linear.bias\n",
      "bert.embeddings.image_layer_norm.weight <- roberta.img_embeddings.img_layer_norm.weight\n",
      "bert.embeddings.image_layer_norm.bias <- roberta.img_embeddings.img_layer_norm.bias\n",
      "bert.embeddings.image_location_layer_norm.weight <- roberta.img_embeddings.pos_layer_norm.weight\n",
      "bert.embeddings.image_location_layer_norm.bias <- roberta.img_embeddings.pos_layer_norm.bias\n",
      "bert.embeddings.image_location_embeddings.weight <- roberta.img_embeddings.pos_linear.weight\n",
      "bert.embeddings.image_location_embeddings.bias <- roberta.img_embeddings.pos_linear.bias\n",
      "bert.encoder.layer.0.attention_self.query.weight <- roberta.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention_self.query.bias <- roberta.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention_self.key.weight <- roberta.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention_self.key.bias <- roberta.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention_self.value.weight <- roberta.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention_self.value.bias <- roberta.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention_output.dense.weight <- roberta.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention_output.dense.bias <- roberta.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention_output.LayerNorm.weight <- roberta.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention_output.LayerNorm.bias <- roberta.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight <- roberta.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias <- roberta.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight <- roberta.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias <- roberta.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight <- roberta.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias <- roberta.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention_self.query.weight <- roberta.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention_self.query.bias <- roberta.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention_self.key.weight <- roberta.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention_self.key.bias <- roberta.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention_self.value.weight <- roberta.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention_self.value.bias <- roberta.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention_output.dense.weight <- roberta.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention_output.dense.bias <- roberta.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention_output.LayerNorm.weight <- roberta.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention_output.LayerNorm.bias <- roberta.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight <- roberta.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias <- roberta.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight <- roberta.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias <- roberta.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight <- roberta.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias <- roberta.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention_self.query.weight <- roberta.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention_self.query.bias <- roberta.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention_self.key.weight <- roberta.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention_self.key.bias <- roberta.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention_self.value.weight <- roberta.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention_self.value.bias <- roberta.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention_output.dense.weight <- roberta.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention_output.dense.bias <- roberta.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention_output.LayerNorm.weight <- roberta.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention_output.LayerNorm.bias <- roberta.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight <- roberta.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias <- roberta.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight <- roberta.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias <- roberta.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight <- roberta.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias <- roberta.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention_self.query.weight <- roberta.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention_self.query.bias <- roberta.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention_self.key.weight <- roberta.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention_self.key.bias <- roberta.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention_self.value.weight <- roberta.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention_self.value.bias <- roberta.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention_output.dense.weight <- roberta.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention_output.dense.bias <- roberta.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention_output.LayerNorm.weight <- roberta.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention_output.LayerNorm.bias <- roberta.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight <- roberta.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias <- roberta.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight <- roberta.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias <- roberta.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight <- roberta.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias <- roberta.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention_self.query.weight <- roberta.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention_self.query.bias <- roberta.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention_self.key.weight <- roberta.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention_self.key.bias <- roberta.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention_self.value.weight <- roberta.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention_self.value.bias <- roberta.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention_output.dense.weight <- roberta.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention_output.dense.bias <- roberta.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention_output.LayerNorm.weight <- roberta.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention_output.LayerNorm.bias <- roberta.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight <- roberta.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias <- roberta.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight <- roberta.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias <- roberta.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight <- roberta.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias <- roberta.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention_self.query.weight <- roberta.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention_self.query.bias <- roberta.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention_self.key.weight <- roberta.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention_self.key.bias <- roberta.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention_self.value.weight <- roberta.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention_self.value.bias <- roberta.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention_output.dense.weight <- roberta.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention_output.dense.bias <- roberta.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention_output.LayerNorm.weight <- roberta.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention_output.LayerNorm.bias <- roberta.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight <- roberta.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias <- roberta.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight <- roberta.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias <- roberta.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight <- roberta.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias <- roberta.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.12.attention_self.query.weight <- roberta.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.12.attention_self.query.bias <- roberta.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.12.attention_self.key.weight <- roberta.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.12.attention_self.key.bias <- roberta.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.12.attention_self.value.weight <- roberta.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.12.attention_self.value.bias <- roberta.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.12.attention_output.dense.weight <- roberta.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.12.attention_output.dense.bias <- roberta.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.12.attention_output.LayerNorm.weight <- roberta.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.12.attention_output.LayerNorm.bias <- roberta.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.13.intermediate.dense.weight <- roberta.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.13.intermediate.dense.bias <- roberta.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.13.output.dense.weight <- roberta.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.13.output.dense.bias <- roberta.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.13.output.LayerNorm.weight <- roberta.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.13.output.LayerNorm.bias <- roberta.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.14.attention_self.query.weight <- roberta.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.14.attention_self.query.bias <- roberta.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.14.attention_self.key.weight <- roberta.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.14.attention_self.key.bias <- roberta.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.14.attention_self.value.weight <- roberta.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.14.attention_self.value.bias <- roberta.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.14.attention_output.dense.weight <- roberta.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.14.attention_output.dense.bias <- roberta.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.14.attention_output.LayerNorm.weight <- roberta.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.14.attention_output.LayerNorm.bias <- roberta.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.15.intermediate.dense.weight <- roberta.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.15.intermediate.dense.bias <- roberta.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.15.output.dense.weight <- roberta.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.15.output.dense.bias <- roberta.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.15.output.LayerNorm.weight <- roberta.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.15.output.LayerNorm.bias <- roberta.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.16.attention_self.query.weight <- roberta.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.16.attention_self.query.bias <- roberta.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.16.attention_self.key.weight <- roberta.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.16.attention_self.key.bias <- roberta.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.16.attention_self.value.weight <- roberta.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.16.attention_self.value.bias <- roberta.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.16.attention_output.dense.weight <- roberta.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.16.attention_output.dense.bias <- roberta.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.16.attention_output.LayerNorm.weight <- roberta.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.16.attention_output.LayerNorm.bias <- roberta.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.17.intermediate.dense.weight <- roberta.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.17.intermediate.dense.bias <- roberta.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.17.output.dense.weight <- roberta.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.17.output.dense.bias <- roberta.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.17.output.LayerNorm.weight <- roberta.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.17.output.LayerNorm.bias <- roberta.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.18.attention_self.query.weight <- roberta.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.18.attention_self.query.bias <- roberta.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.18.attention_self.key.weight <- roberta.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.18.attention_self.key.bias <- roberta.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.18.attention_self.value.weight <- roberta.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.18.attention_self.value.bias <- roberta.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.18.attention_output.dense.weight <- roberta.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.18.attention_output.dense.bias <- roberta.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.18.attention_output.LayerNorm.weight <- roberta.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.18.attention_output.LayerNorm.bias <- roberta.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.19.intermediate.dense.weight <- roberta.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.19.intermediate.dense.bias <- roberta.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.19.output.dense.weight <- roberta.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.19.output.dense.bias <- roberta.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.19.output.LayerNorm.weight <- roberta.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.19.output.LayerNorm.bias <- roberta.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.20.attention_self.query.weight <- roberta.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.20.attention_self.query.bias <- roberta.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.20.attention_self.key.weight <- roberta.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.20.attention_self.key.bias <- roberta.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.20.attention_self.value.weight <- roberta.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.20.attention_self.value.bias <- roberta.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.20.attention_output.dense.weight <- roberta.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.20.attention_output.dense.bias <- roberta.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.20.attention_output.LayerNorm.weight <- roberta.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.20.attention_output.LayerNorm.bias <- roberta.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.21.intermediate.dense.weight <- roberta.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.21.intermediate.dense.bias <- roberta.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.21.output.dense.weight <- roberta.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.21.output.dense.bias <- roberta.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.21.output.LayerNorm.weight <- roberta.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.21.output.LayerNorm.bias <- roberta.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.22.attention_self.query.weight <- roberta.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.22.attention_self.query.bias <- roberta.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.22.attention_self.key.weight <- roberta.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.22.attention_self.key.bias <- roberta.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.22.attention_self.value.weight <- roberta.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.22.attention_self.value.bias <- roberta.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.22.attention_output.dense.weight <- roberta.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.22.attention_output.dense.bias <- roberta.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.22.attention_output.LayerNorm.weight <- roberta.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.22.attention_output.LayerNorm.bias <- roberta.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.23.intermediate.dense.weight <- roberta.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.23.intermediate.dense.bias <- roberta.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.23.output.dense.weight <- roberta.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.23.output.dense.bias <- roberta.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.23.output.LayerNorm.weight <- roberta.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.23.output.LayerNorm.bias <- roberta.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.t_pooler.dense.weight <- roberta.pooler.dense.weight\n",
      "bert.t_pooler.dense.bias <- roberta.pooler.dense.bias\n",
      "cls.predictions.bias <- cls.bias\n",
      "cls.predictions.transform.dense.weight <- cls.dense.weight\n",
      "cls.predictions.transform.dense.bias <- cls.dense.bias\n",
      "cls.predictions.transform.LayerNorm.weight <- cls.layer_norm.weight\n",
      "cls.predictions.transform.LayerNorm.bias <- cls.layer_norm.bias\n",
      "cls.predictions.decoder.weight <- cls.decoder.weight\n",
      "cls.bi_seq_relationship.weight <- itm_output.weight\n",
      "cls.bi_seq_relationship.bias <- itm_output.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply mapping\n",
    "for trg, src in volta2original.items():\n",
    "    print(trg, '<-', src)\n",
    "    assert trg_dict[trg].shape == original_ckpt[src].shape\n",
    "    trg_dict[trg] = original_ckpt[src]\n",
    "model.load_state_dict(trg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(768)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model.state_dict()['bert.t_pooler.dense.bias'] == uc2['roberta.pooler.dense.bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(768)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model.state_dict()['bert.encoder.layer.22.attention_self.key.bias'] == model.state_dict()['bert.encoder.layer.22.attention_self.v_key.bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2359296)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.state_dict()['bert.encoder.layer.23.intermediate.dense.weight'] == model.state_dict()['bert.encoder.layer.23.intermediate.v_dense.weight']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2359296"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['bert.encoder.layer.23.intermediate.dense.weight'].size(0) * model.state_dict()['bert.encoder.layer.23.intermediate.dense.weight'].size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UC2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import json\n",
    "\n",
    "import msgpack\n",
    "import msgpack_numpy\n",
    "msgpack_numpy.patch()\n",
    "\n",
    "db_name = \"../../flickr30k/feat_th0.2_max100_min10\"\n",
    "nbb = \"../../flickr30k/nbb_th0.2_max100_min10.json\"\n",
    "name2nbb = json.load(open(f'{nbb}'))\n",
    "\n",
    "env = lmdb.open(f'{db_name}',readonly=True, create=False)\n",
    "txn = env.begin(buffers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"flickr30k_002102835360.npz\"\n",
    "dump = txn.get(filename.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<memory at 0x7f9d2236be88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_nbb = name2nbb[filename]\n",
    "_nbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dump = msgpack.loads(dump, raw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.      , 0.3228  , 0.209   , 0.7686  , 0.209   , 0.446   ],\n",
       "       [0.2742  , 0.7817  , 0.4968  , 0.9985  , 0.2227  , 0.2164  ],\n",
       "       [0.00809 , 0.2183  , 0.11865 , 0.2722  , 0.11053 , 0.05408 ],\n",
       "       [0.      , 0.2064  , 0.1469  , 0.9985  , 0.1469  , 0.792   ],\n",
       "       [0.2632  , 0.3118  , 0.5825  , 0.8413  , 0.319   , 0.53    ],\n",
       "       [0.826   , 0.703   , 0.8657  , 0.801   , 0.03973 , 0.0979  ],\n",
       "       [0.8726  , 0.8184  , 0.98    , 0.9985  , 0.1072  , 0.1797  ],\n",
       "       [0.6143  , 0.4531  , 0.9526  , 0.957   , 0.3386  , 0.504   ],\n",
       "       [0.564   , 0.2546  , 0.8647  , 0.7417  , 0.3008  , 0.4873  ],\n",
       "       [0.      , 0.1522  , 0.774   , 0.848   , 0.774   , 0.6963  ],\n",
       "       [0.769   , 0.7026  , 0.8555  , 0.8174  , 0.0863  , 0.1149  ],\n",
       "       [0.2183  , 0.      , 0.6304  , 0.9985  , 0.4124  , 0.9985  ],\n",
       "       [0.6836  , 0.1381  , 0.808   , 0.205   , 0.1245  , 0.0669  ],\n",
       "       [0.73    , 0.      , 0.9995  , 0.9985  , 0.2693  , 0.9985  ],\n",
       "       [0.657   , 0.05008 , 0.823   , 0.1986  , 0.166   , 0.1486  ],\n",
       "       [0.8154  , 0.256   , 0.925   , 0.355   , 0.109   , 0.09894 ],\n",
       "       [0.615   , 0.06476 , 0.8433  , 0.841   , 0.228   , 0.7764  ],\n",
       "       [0.08514 , 0.185   , 0.2329  , 0.9507  , 0.1477  , 0.7656  ],\n",
       "       [0.6177  , 0.1671  , 0.6953  , 0.2494  , 0.07764 , 0.0823  ],\n",
       "       [0.      , 0.682   , 0.2036  , 0.9985  , 0.2036  , 0.3164  ],\n",
       "       [0.672   , 0.04367 , 0.8223  , 0.2554  , 0.1504  , 0.2115  ],\n",
       "       [0.0244  , 0.745   , 0.184   , 0.9985  , 0.1595  , 0.2532  ],\n",
       "       [0.4702  , 0.1858  , 0.899   , 0.9985  , 0.429   , 0.8125  ],\n",
       "       [0.8335  , 0.3604  , 0.8955  , 0.47    , 0.06195 , 0.10974 ],\n",
       "       [0.1621  , 0.1984  , 0.6606  , 0.9985  , 0.4988  , 0.8     ],\n",
       "       [0.482   , 0.1667  , 0.6494  , 0.865   , 0.1674  , 0.6987  ],\n",
       "       [0.001793, 0.1243  , 0.1346  , 0.3516  , 0.1328  , 0.2273  ],\n",
       "       [0.4573  , 0.2075  , 0.6196  , 0.902   , 0.1625  , 0.6943  ]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dump['norm_bb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22260000000000002"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4968-0.2742"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4458"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7686-0.3228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
